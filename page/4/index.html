<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/4/">





  <title>Hexo</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/17-pagerank/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/17-pagerank/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wyg.day09._3product;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wyg0405@gmail.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@description</span>: goods.txt</span></span><br><span class="line"><span class="comment"> * 1   0  电器</span></span><br><span class="line"><span class="comment"> * 2   0  食品</span></span><br><span class="line"><span class="comment"> * 3   0  服饰</span></span><br><span class="line"><span class="comment"> * 4   1  冰箱</span></span><br><span class="line"><span class="comment"> * 5   1  彩电</span></span><br><span class="line"><span class="comment"> * 6   2  肉类</span></span><br><span class="line"><span class="comment"> * 7   2  蔬菜</span></span><br><span class="line"><span class="comment"> * 8   3  鞋子</span></span><br><span class="line"><span class="comment"> * 9   3  裤子</span></span><br><span class="line"><span class="comment"> * 10  4  海尔</span></span><br><span class="line"><span class="comment"> * 11  4  美的</span></span><br><span class="line"><span class="comment"> * 12  5  创维</span></span><br><span class="line"><span class="comment"> * 13  5  海信</span></span><br><span class="line"><span class="comment"> * 14  6  牛肉</span></span><br><span class="line"><span class="comment"> * 15  6  羊肉</span></span><br><span class="line"><span class="comment"> * 16  7  白菜</span></span><br><span class="line"><span class="comment"> * 17  7  空心菜</span></span><br><span class="line"><span class="comment"> * 18  8  耐克</span></span><br><span class="line"><span class="comment"> * 19  8  阿迪达斯</span></span><br><span class="line"><span class="comment"> * 20  9  才子</span></span><br><span class="line"><span class="comment"> * 21  9  海澜之家</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * 结果</span></span><br><span class="line"><span class="comment"> * 10  0  电器-冰箱-海尔</span></span><br><span class="line"><span class="comment"> * 11  0  电器-冰箱-美的</span></span><br><span class="line"><span class="comment"> * 12  0  电器-彩电-创维</span></span><br><span class="line"><span class="comment"> * 13  0  电器-彩电-海信</span></span><br><span class="line"><span class="comment"> * 14  0  食品-肉类-牛肉</span></span><br><span class="line"><span class="comment"> * 15  0  食品-肉类-羊肉</span></span><br><span class="line"><span class="comment"> * 16  0  食品-蔬菜-白菜</span></span><br><span class="line"><span class="comment"> * 17  0  食品-蔬菜-空心菜</span></span><br><span class="line"><span class="comment"> * 18  0  服饰-鞋子-耐克</span></span><br><span class="line"><span class="comment"> * 19  0  服饰-鞋子-阿迪达斯</span></span><br><span class="line"><span class="comment"> * 20  0  服饰-裤子-才子</span></span><br><span class="line"><span class="comment"> * 21  0  服饰-裤子-海澜之家</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span> 2019-03-01 下午2:55</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        IntWritable k = <span class="keyword">new</span> IntWritable();</span><br><span class="line">        Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            String[] lines = value.toString().split(<span class="string">"\t"</span>);</span><br><span class="line">            <span class="keyword">if</span> (<span class="string">"0"</span>.equals(lines[<span class="number">1</span>])) &#123;</span><br><span class="line">                k.set(Integer.parseInt(lines[<span class="number">0</span>]));</span><br><span class="line">                v.set(lines[<span class="number">1</span>] + <span class="string">"\t"</span> + lines[<span class="number">2</span>]);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                k.set(Integer.parseInt(lines[<span class="number">1</span>]));</span><br><span class="line">                v.set(lines[<span class="number">0</span>] + <span class="string">"\t"</span> + lines[<span class="number">2</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">            context.write(k, v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">        IntWritable k = <span class="keyword">new</span> IntWritable();</span><br><span class="line">        Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(IntWritable key, Iterable&lt;Text&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            String parent = <span class="string">""</span>;</span><br><span class="line">            List&lt;String&gt; children = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (Text value : values) &#123;</span><br><span class="line">                <span class="keyword">if</span> (value.toString().startsWith(<span class="string">"0"</span>)) &#123;</span><br><span class="line">                    parent = value.toString();</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    children.add(value.toString());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (children.size() == <span class="number">0</span>) &#123;</span><br><span class="line">                v.set(parent);</span><br><span class="line">                context.write(key, v);</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">""</span>.equals(parent)) &#123;</span><br><span class="line">                <span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line">                    k.set(Integer.parseInt(child.split(<span class="string">"\t"</span>)[<span class="number">0</span>]));</span><br><span class="line">                    v.set(key.get() + <span class="string">"\t"</span> + child.split(<span class="string">"\t"</span>)[<span class="number">1</span>]);</span><br><span class="line">                    context.write(k, v);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">for</span> (String child : children) &#123;</span><br><span class="line">                    k.set(Integer.parseInt(child.split(<span class="string">"\t"</span>)[<span class="number">0</span>]));</span><br><span class="line">                    v.set(parent + <span class="string">"-"</span> + child.split(<span class="string">"\t"</span>)[<span class="number">1</span>]);</span><br><span class="line">                    context.write(k, v);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">//加载配置文件</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"hadoop"</span>);</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://hadoop1:9000"</span>);</span><br><span class="line">        <span class="comment">//使 NameNode 返回 DataNode 的主机名而不是 IP</span></span><br><span class="line">        conf.set(<span class="string">"dfs.client.use.datanode.hostname"</span>, <span class="string">"true"</span>);</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">3</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++) &#123;</span><br><span class="line">            <span class="comment">//启动一个Job</span></span><br><span class="line">            Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//计算程序主驱动类</span></span><br><span class="line">            job.setJarByClass(Product.class);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//设置Mapper及其key,value类型</span></span><br><span class="line">            job.setMapperClass(MyMapper.class);</span><br><span class="line">            job.setMapOutputKeyClass(IntWritable.class);</span><br><span class="line">            job.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">            <span class="comment">//设置reducer及其key,value类型</span></span><br><span class="line">            job.setReducerClass(MyReducer.class);</span><br><span class="line">            job.setOutputKeyClass(IntWritable.class);</span><br><span class="line">            job.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment">//输入路径</span></span><br><span class="line">            <span class="keyword">if</span> (i == <span class="number">0</span>) &#123;</span><br><span class="line">                FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(<span class="string">"/input/goods"</span>));</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(<span class="string">"/output/goods/"</span> + count + <span class="string">"/"</span> + (i - <span class="number">1</span>)));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">//输出路径,该路径不能存在</span></span><br><span class="line">            FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"/output/goods/"</span> + count + <span class="string">"/"</span> + i));</span><br><span class="line"></span><br><span class="line">            <span class="comment">//启动job</span></span><br><span class="line">            <span class="comment">//job.submit();//无日志</span></span><br><span class="line">            job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/16.job提交过程/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/16.job提交过程/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>job提交过程</p>
<p>1.jar包只上传在一个节点，但其他节点的maptask和reducetask也可以运行？</p>
<p>每次运行job的时候都会在hdfs上生成一个和jobid相同的 目录，hadoop fs -ls /tmp/hadoop-yarn/staging/hadoop/.staging/jobid.这个目录存放的是运行程序的公共资源，即maptask和reducetask运行过程中的通用资源，比如jar包，配置文件，3个核心文件</p>
<p>job.jar</p>
<p>job.spilt 切片信息</p>
<p>job.xml   job运行参数</p>
<p>maptask和reducetask运行时需要则从hdfs拉取到本地，/home/hadoop/data/hadoop/tmp/nm-local-dir</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/15-yarn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/15-yarn/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="yarn"><a href="#yarn" class="headerlink" title="yarn"></a>yarn</h1><h2 id="1-Hadoop1-0时代"><a href="#1-Hadoop1-0时代" class="headerlink" title="1.Hadoop1.0时代"></a>1.Hadoop1.0时代</h2><p>​    jobtracker,资源调度，随机调度，监控程序运行状态，启动运行程序</p>
<p>​    tasktracker,负责计算程序的执行，将计算资源分成两部分，mapslot和reduceslot,每部分资源只能跑对应任务</p>
<p>缺陷：</p>
<ol>
<li>单点故障</li>
<li>资源调度随机，造成资源浪费</li>
<li>jobtracker压力过大</li>
</ol>
<h2 id="2-hadoop2-0"><a href="#2-hadoop2-0" class="headerlink" title="2.hadoop2.0"></a>2.hadoop2.0</h2><p>resourcemanager:</p>
<ol>
<li>接收客户端运行程序的请求</li>
<li>接收nodemanager的状态报告，即nodemanager的资源状态和存活状况</li>
<li>整个计算程序的资源调度</li>
</ol>
<p>nodemanager:</p>
<ol>
<li>接收resourcemanager命令</li>
<li>提供资源运行计算程序</li>
</ol>
<p>MRAppMaster:单个计算程序的老大，负责帮助计算程序向resourcemanager申请资源，负责启动maptask和reducetask任务，并监控maptask和reducetask的运行进度</p>
<p>appliactionsmanager:所有应用管理者，负责调度应用程序</p>
<p>container:抽象的资源容器，封装一定的cpu,io,和网络资源，是maptask,reducetask等运行资源单位，</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/14-MapReduce shuffle过程/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/14-MapReduce shuffle过程/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="MapReduce-shuffle过程"><a href="#MapReduce-shuffle过程" class="headerlink" title="MapReduce shuffle过程"></a>MapReduce shuffle过程</h1><h2 id="一、MapReduce计算模型"><a href="#一、MapReduce计算模型" class="headerlink" title="一、MapReduce计算模型"></a>一、MapReduce计算模型</h2><p>​    我们知道MapReduce计算模型主要由三个阶段构成：Map、shuffle、Reduce。</p>
<p>​    Map是映射，负责数据的过滤分法，将原始数据转化为键值对；Reduce是合并，将具有相同key值的value进行处理后再输出新的键值对作为最终结果。为了让Reduce可以并行处理Map的结果，必须对Map的输出进行一定的排序与分割，然后再交给对应的Reduce，而这个将Map输出进行进一步整理并交给Reduce的过程就是Shuffle。整个MR的大致过程如下：</p>
<p><img src="14-shuffle.assets/20151017151302759" alt="这里写图片描述"></p>
<p>​    Map和Reduce操作需要我们自己定义相应Map类和Reduce类，以完成我们所需要的化简、合并操作，而shuffle则是系统自动帮我们实现的，了解shuffle的具体流程能帮助我们编写出更加高效的Mapreduce程序。</p>
<p>Shuffle过程包含在Map和Reduce两端，即Map shuffle和Reduce shuffle</p>
<h2 id="二、Map-shuffle"><a href="#二、Map-shuffle" class="headerlink" title="二、Map shuffle"></a>二、Map shuffle</h2><p>​    在Map端的shuffle过程是对Map的结果进行分区、排序、分割，然后将属于同一划分（分区）的输出合并在一起并写在磁盘上，最终得到一个分区有序的文件，分区有序的含义是map输出的键值对按分区进行排列，具有相同partition值的键值对存储在一起，每个分区里面的键值对又按key值进行升序排列（默认），其流程大致如下：</p>
<p><img src="14-shuffle.assets/20151017160804118" alt="这里写图片描述"></p>
<h3 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h3><p>​    对于map输出的每一个键值对，系统都会给定一个partition，partition值默认是通过计算key的hash值后对Reduce task的数量取模获得。如果一个键值对的partition值为1，意味着这个键值对会交给第一个Reducer处理。</p>
<p>​    我们知道每一个Reduce的输出都是有序的，但是将所有Reduce的输出合并到一起却并非是全局有序的，如果要做到全局有序，我们该怎么做呢？最简单的方式，只设置一个Reduce task，但是这样完全发挥不出集群的优势，而且能应对的数据量也很受限。最佳的方式是自己定义一个Partitioner，用输入数据的最大值除以系统Reduce task数量的商作为分割边界，也就是说分割数据的边界为此商的1倍、2倍至numPartitions-1倍，这样就能保证执行partition后的数据是整体有序的。</p>
<p>​    另一种需要我们自己定义一个Partitioner的情况是各个Reduce task处理的键值对数量极不平衡。对于某些数据集，由于很多不同的key的hash值都一样，导致这些键值对都被分给同一个Reducer处理，而其他的Reducer处理的键值对很少，从而拖延整个任务的进度。当然，编写自己的Partitioner必须要保证具有相同key值的键值对分发到同一个Reducer。</p>
<h3 id="Collector"><a href="#Collector" class="headerlink" title="Collector"></a>Collector</h3><p>​    Map的输出结果是由collector处理的，每个Map任务不断地将键值对输出到在内存中构造的一个环形数据结构中。使用环形数据结构是为了更有效地使用内存空间，在内存中放置尽可能多的数据。</p>
<p>​    这个数据结构其实就是个字节数组，叫Kvbuffer，名如其义，但是这里面不光放置了数据，还放置了一些索引数据，给放置索引数据的区域起了一个Kvmeta的别名，在Kvbuffer的一块区域上穿了一个IntBuffer（字节序采用的是平台自身的字节序）的马甲。数据区域和索引数据区域在Kvbuffer中是相邻不重叠的两个区域，用一个分界点来划分两者，分界点不是亘古不变的，而是每次Spill之后都会更新一次。初始的分界点是0，数据的存储方向是向上增长，索引数据的存储方向是向下增长，如图所示：</p>
<p><img src="14-shuffle.assets/20151017165918130-1550737009488" alt="这里写图片描述"></p>
<p>​    Kvbuffer的存放指针bufindex是一直闷着头地向上增长，比如bufindex初始值为0，一个Int型的key写完之后，bufindex增长为4，一个Int型的value写完之后，bufindex增长为8。</p>
<p>​    索引是对在kvbuffer中的键值对的索引，是个四元组，包括：value的起始位置、key的起始位置、partition值、value的长度，占用四个Int长度，Kvmeta的存放指针Kvindex每次都是向下跳四个“格子”，然后再向上一个格子一个格子地填充四元组的数据。比如Kvindex初始位置是-4，当第一个键值对写完之后，(Kvindex+0)的位置存放value的起始位置、(Kvindex+1)的位置存放key的起始位置、(Kvindex+2)的位置存放partition的值、(Kvindex+3)的位置存放value的长度，然后Kvindex跳到-8位置，等第二个键值对和索引写完之后，Kvindex跳到-12位置。</p>
<p>​    Kvbuffer的大小可以通过io.sort.mb设置，默认大小为100M。但不管怎么设置，Kvbuffer的容量都是有限的，键值对和索引不断地增加，加着加着，Kvbuffer总有不够用的那天，那怎么办？把数据从内存刷到磁盘上再接着往内存写数据，把Kvbuffer中的数据刷到磁盘上的过程就叫Spill，多么明了的叫法，内存中的数据满了就自动地spill到具有更大空间的磁盘。</p>
<p>​    关于Spill触发的条件，也就是Kvbuffer用到什么程度开始Spill，还是要讲究一下的。如果把Kvbuffer用得死死得，一点缝都不剩的时候再开始Spill，那Map任务就需要等Spill完成腾出空间之后才能继续写数据；如果Kvbuffer只是满到一定程度，比如80%的时候就开始Spill，那在Spill的同时，Map任务还能继续写数据，如果Spill够快，Map可能都不需要为空闲空间而发愁。两利相衡取其大，一般选择后者。Spill的门限可以通过io.sort.spill.percent，默认是0.8。</p>
<p>​    Spill这个重要的过程是由Spill线程承担，Spill线程从Map任务接到“命令”之后就开始正式干活，干的活叫SortAndSpill，原来不仅仅是Spill，在Spill之前还有个颇具争议性的Sort。</p>
<h3 id="Sort"><a href="#Sort" class="headerlink" title="Sort"></a>Sort</h3><p>​    当Spill触发后，SortAndSpill先把Kvbuffer中的数据按照partition值和key两个关键字升序排序，移动的只是索引数据，排序结果是Kvmeta中数据按照partition为单位聚集在一起，同一partition内的按照key有序。</p>
<h3 id="Spill"><a href="#Spill" class="headerlink" title="Spill"></a>Spill</h3><p>​    Spill线程为这次Spill过程创建一个磁盘文件：从所有的本地目录中轮训查找能存储这么大空间的目录，找到之后在其中创建一个类似于“spill12.out”的文件。Spill线程根据排过序的Kvmeta挨个partition的把数据吐到这个文件中，一个partition对应的数据吐完之后顺序地吐下个partition，直到把所有的partition遍历完。一个partition在文件中对应的数据也叫段(segment)。在这个过程中如果用户配置了combiner类，那么在写之前会先调用combineAndSpill()，对结果进行进一步合并后再写出。Combiner会优化MapReduce的中间结果，所以它在整个模型中会多次使用。那哪些场景才能使用Combiner呢？Combiner的输出是Reducer的输入，Combiner绝不能改变最终的计算结果。所以从我的想法来看，Combiner只应该用于那种Reduce的输入key/value与输出key/value类型完全一致，且不影响最终结果的场景。比如累加，最大值等。Combiner的使用一定得慎重，如果用好，它对job执行效率有帮助，反之会影响reduce的最终结果。</p>
<p>​    所有的partition对应的数据都放在这个文件里，虽然是顺序存放的，但是怎么直接知道某个partition在这个文件中存放的起始位置呢？强大的索引又出场了。有一个三元组记录某个partition对应的数据在这个文件中的索引：起始位置、原始数据长度、压缩之后的数据长度，一个partition对应一个三元组。然后把这些索引信息存放在内存中，如果内存中放不下了，后续的索引信息就需要写到磁盘文件中了：从所有的本地目录中轮训查找能存储这么大空间的目录，找到之后在其中创建一个类似于“spill12.out.index”的文件，文件中不光存储了索引数据，还存储了crc32的校验数据。spill12.out.index不一定在磁盘上创建，如果内存（默认1M空间）中能放得下就放在内存中，即使在磁盘上创建了，和spill12.out文件也不一定在同一个目录下。每一次Spill过程就会最少生成一个out文件，有时还会生成index文件，Spill的次数也烙印在文件名中。索引文件和数据文件的对应关系如下图所示：</p>
<p><img src="14-shuffle.assets/20151017173908750" alt="这里写图片描述"></p>
<p>​    在Spill线程如火如荼的进行SortAndSpill工作的同时，Map任务不会因此而停歇，而是一无既往地进行着数据输出。Map还是把数据写到kvbuffer中，那问题就来了：只顾着闷头按照bufindex指针向上增长，kvmeta只顾着按照Kvindex向下增长，是保持指针起始位置不变继续跑呢，还是另谋它路？如果保持指针起始位置不变，很快bufindex和Kvindex就碰头了，碰头之后再重新开始或者移动内存都比较麻烦，不可取。Map取kvbuffer中剩余空间的中间位置，用这个位置设置为新的分界点，bufindex指针移动到这个分界点，Kvindex移动到这个分界点的-16位置，然后两者就可以和谐地按照自己既定的轨迹放置数据了，当Spill完成，空间腾出之后，不需要做任何改动继续前进。分界点的转换如下图所示：</p>
<p>​    Map任务总要把输出的数据写到磁盘上，即使输出数据量很小在内存中全部能装得下，在最后也会把数据刷到磁盘上。</p>
<h3 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h3><p>​    Map任务如果输出数据量很大，可能会进行好几次Spill，out文件和Index文件会产生很多，分布在不同的磁盘上。最后把这些文件进行合并的merge过程闪亮登场。</p>
<p>​    Merge过程怎么知道产生的Spill文件都在哪了呢？从所有的本地目录上扫描得到产生的Spill文件，然后把路径存储在一个数组里。Merge过程又怎么知道Spill的索引信息呢？没错，也是从所有的本地目录上扫描得到Index文件，然后把索引信息存储在一个列表里。到这里，又遇到了一个值得纳闷的地方。在之前Spill过程中的时候为什么不直接把这些信息存储在内存中呢，何必又多了这步扫描的操作？特别是Spill的索引数据，之前当内存超限之后就把数据写到磁盘，现在又要从磁盘把这些数据读出来，还是需要装到更多的内存中。之所以多此一举，是因为这时kvbuffer这个内存大户已经不再使用可以回收，有内存空间来装这些数据了。（对于内存空间较大的土豪来说，用内存来省却这两个io步骤还是值得考虑的。）</p>
<p><img src="14-shuffle.assets/20151017180604215" alt="这里写图片描述"></p>
<p>​    然后为merge过程创建一个叫file.out的文件和一个叫file.out.Index的文件用来存储最终的输出和索引，一个partition一个partition的进行合并输出。对于某个partition来说，从索引列表中查询这个partition对应的所有索引信息，每个对应一个段插入到段列表中。也就是这个partition对应一个段列表，记录所有的Spill文件中对应的这个partition那段数据的文件名、起始位置、长度等等。</p>
<p>​    然后对这个partition对应的所有的segment进行合并，目标是合并成一个segment。当这个partition对应很多个segment时，会分批地进行合并：先从segment列表中把第一批取出来，以key为关键字放置成最小堆，然后从最小堆中每次取出最小的输出到一个临时文件中，这样就把这一批段合并成一个临时的段，把它加回到segment列表中；再从segment列表中把第二批取出来合并输出到一个临时segment，把其加入到列表中；这样往复执行，直到剩下的段是一批，输出到最终的文件中。最终的索引数据仍然输出到Index文件中。</p>
<h2 id="三、Reduce-shuffle"><a href="#三、Reduce-shuffle" class="headerlink" title="三、Reduce shuffle"></a>三、Reduce shuffle</h2><p>​    在Reduce端，shuffle主要分为复制Map输出、排序合并两个阶段。</p>
<h3 id="Copy"><a href="#Copy" class="headerlink" title="Copy"></a>Copy</h3><p>​    Reduce任务通过HTTP向各个Map任务拖取它所需要的数据。Map任务成功完成后，会通知父TaskTracker状态已经更新，TaskTracker进而通知JobTracker（这些通知在心跳机制中进行）。所以，对于指定作业来说，JobTracker能记录Map输出和TaskTracker的映射关系。Reduce会定期向JobTracker获取Map的输出位置，一旦拿到输出位置，Reduce任务就会从此输出对应的TaskTracker上复制输出到本地，而不会等到所有的Map任务结束。</p>
<h3 id="Merge-Sort"><a href="#Merge-Sort" class="headerlink" title="Merge Sort"></a>Merge Sort</h3><p>​    Copy过来的数据会先放入内存缓冲区中，如果内存缓冲区中能放得下这次数据的话就直接把数据写到内存中，即内存到内存merge。Reduce要向每个Map去拖取数据，在内存中每个Map对应一块数据，当内存缓存区中存储的Map数据占用空间达到一定程度的时候，开始启动内存中merge，把内存中的数据merge输出到磁盘上一个文件中，即内存到磁盘merge。在将buffer中多个map输出合并写入磁盘之前，如果设置了Combiner，则会化简压缩合并的map输出。Reduce的内存缓冲区可通过mapred.job.shuffle.input.buffer.percent配置，默认是JVM的heap size的70%。内存到磁盘merge的启动门限可以通过mapred.job.shuffle.merge.percent配置，默认是66%。</p>
<p>​    当属于该reducer的map输出全部拷贝完成，则会在reducer上生成多个文件（如果拖取的所有map数据总量都没有内存缓冲区，则数据就只存在于内存中），这时开始执行合并操作，即磁盘到磁盘merge，Map的输出数据已经是有序的，Merge进行一次合并排序，所谓Reduce端的sort过程就是这个合并的过程。一般Reduce是一边copy一边sort，即copy和sort两个阶段是重叠而不是完全分开的。最终Reduce shuffle过程会输出一个整体有序的数据块。</p>
<p>以上就是我对shuffle过程的理解，如有不对之处还请指正<br>参考：<br><a href="http://www.csdn.net/article/2014-05-19/2819831-TDW-Shuffle/1" target="_blank" rel="noopener">http://www.csdn.net/article/2014-05-19/2819831-TDW-Shuffle/1</a><br><a href="http://blog.csdn.net/xiaolang85/article/details/8528892" target="_blank" rel="noopener">http://blog.csdn.net/xiaolang85/article/details/8528892</a><br><a href="http://shiyanjun.cn/archives/588.html" target="_blank" rel="noopener">http://shiyanjun.cn/archives/588.html</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/13-reduce端join与map端join/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/13-reduce端join与map端join/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="reduce端join与map端join"><a href="#reduce端join与map端join" class="headerlink" title="reduce端join与map端join"></a>reduce端join与map端join</h1><h2 id="reduce端join"><a href="#reduce端join" class="headerlink" title="reduce端join"></a>reduce端join</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wyg.day10_join;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.InputSplit;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileSplit;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * DESCRIPTION:</span></span><br><span class="line"><span class="comment"> * 两表join</span></span><br><span class="line"><span class="comment"> * order</span></span><br><span class="line"><span class="comment"> * 0001    p002   2  20190216</span></span><br><span class="line"><span class="comment"> * 0002    p001   3  20190216</span></span><br><span class="line"><span class="comment"> * 0003    p002   4  20190216</span></span><br><span class="line"><span class="comment"> * 0004    p001   5  20190216</span></span><br><span class="line"><span class="comment"> * 0005    p003   7  20190216</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * product</span></span><br><span class="line"><span class="comment"> * p001    小米 mobile 2000.00</span></span><br><span class="line"><span class="comment"> * p002 锤子 mobile 1998.00</span></span><br><span class="line"><span class="comment"> * p003    华为 mobile  4488.00</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * 结果</span></span><br><span class="line"><span class="comment"> * p001    0004   5  20190216   小米 mobile 2000.00</span></span><br><span class="line"><span class="comment"> * p001    0002   3  20190216   小米 mobile 2000.00</span></span><br><span class="line"><span class="comment"> * p002    0003   4  20190216   锤子 mobile 1998.00</span></span><br><span class="line"><span class="comment"> * p002    0001   2  20190216   锤子 mobile 1998.00</span></span><br><span class="line"><span class="comment"> * p003    0005   7  20190216   华为 mobile 4488.00</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wyg0405@gmail.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span> 2019-02-17 下午9:48</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Order</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">//加载配置文件</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"hadoop"</span>);</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://hadoop1:9000"</span>);</span><br><span class="line">        <span class="comment">//使 NameNode 返回 DataNode 的主机名而不是 IP</span></span><br><span class="line">        conf.set(<span class="string">"dfs.client.use.datanode.hostname"</span>, <span class="string">"true"</span>);</span><br><span class="line">        <span class="comment">//启动一个Job</span></span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算程序主驱动类</span></span><br><span class="line">        job.setJarByClass(Order.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置Mapper及其key,value类型</span></span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置reducer及其key,value类型</span></span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//输入路径</span></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(<span class="string">"/input/order"</span>));</span><br><span class="line">        <span class="comment">//输出路径,该路径不能存在</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"/output/order/12"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//启动job</span></span><br><span class="line">        <span class="comment">//job.submit();//无日志</span></span><br><span class="line">        job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        String name;</span><br><span class="line">        Text k = <span class="keyword">new</span> Text();</span><br><span class="line">        Text v = <span class="keyword">new</span> Text();</span><br><span class="line">        StringBuffer sb;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 该方法在初始化调用一次</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            InputSplit inputSplit = context.getInputSplit();</span><br><span class="line">            FileSplit fileSplit = (FileSplit) inputSplit;</span><br><span class="line">            name = fileSplit.getPath().getName();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            String[] line = value.toString().split(<span class="string">"\t"</span>);</span><br><span class="line">            sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">            <span class="comment">//关联字段为key</span></span><br><span class="line">            <span class="keyword">if</span> (name.startsWith(<span class="string">"order"</span>)) &#123;<span class="comment">//订单表</span></span><br><span class="line">                k.set(line[<span class="number">1</span>]);</span><br><span class="line">                <span class="comment">//v要打标记，不要过长</span></span><br><span class="line">                v.set(sb.append(<span class="string">"order"</span>).append(line[<span class="number">0</span>]).append(<span class="string">"\t"</span>).append(line[<span class="number">2</span>]).append(<span class="string">"\t"</span>).append(line[<span class="number">3</span>]).toString());</span><br><span class="line">                context.write(k, v);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;<span class="comment">//商品表</span></span><br><span class="line">                k.set(line[<span class="number">0</span>]);</span><br><span class="line">                v.set(sb.append(<span class="string">"product"</span>).append(line[<span class="number">1</span>]).append(<span class="string">"\t"</span>).append(line[<span class="number">2</span>]).append(<span class="string">"\t"</span>).append(line[<span class="number">3</span>]).toString());</span><br><span class="line">                context.write(k, v);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">        Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="comment">//两表为多对一关系，将多的拼接到一</span></span><br><span class="line">            List&lt;String&gt; orderList = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">            List&lt;String&gt; productList = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">            <span class="keyword">for</span> (Text v : values) &#123;</span><br><span class="line">                String line = v.toString();</span><br><span class="line">                <span class="keyword">if</span> (line.startsWith(<span class="string">"order"</span>)) &#123;</span><br><span class="line">                    orderList.add(line.substring(<span class="number">5</span>));</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (line.startsWith(<span class="string">"product"</span>)) &#123;</span><br><span class="line">                    productList.add(line.substring(<span class="number">7</span>));<span class="comment">//理论上就一条数据</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (orderList.size() &gt; <span class="number">0</span> &amp;&amp; productList.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">for</span> (String order : orderList) &#123;</span><br><span class="line">                    v.set(order + <span class="string">"\t"</span> + productList.get(<span class="number">0</span>));</span><br><span class="line">                    context.write(key, v);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>reduce端join缺陷</code> </p>
<blockquote>
<ol>
<li>reducetask并行度不高，建议个数为0.95*datanode节点个数</li>
<li>容器性能</li>
<li>reducetask容易产生数据倾斜</li>
</ol>
</blockquote>
<h2 id="map端join"><a href="#map端join" class="headerlink" title="map端join"></a>map端join</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wyg.day10_join;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.FileReader;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.net.URI;</span><br><span class="line"><span class="keyword">import</span> java.net.URISyntaxException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * DESCRIPTION:map端join</span></span><br><span class="line"><span class="comment"> * 两表join</span></span><br><span class="line"><span class="comment"> * order</span></span><br><span class="line"><span class="comment"> * 0001    p002   2  20190216</span></span><br><span class="line"><span class="comment"> * 0002    p001   3  20190216</span></span><br><span class="line"><span class="comment"> * 0003    p002   4  20190216</span></span><br><span class="line"><span class="comment"> * 0004    p001   5  20190216</span></span><br><span class="line"><span class="comment"> * 0005    p003   7  20190216</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * product</span></span><br><span class="line"><span class="comment"> * p001    小米 mobile 2000.00</span></span><br><span class="line"><span class="comment"> * p002 锤子 mobile 1998.00</span></span><br><span class="line"><span class="comment"> * p003    华为 mobile  4488.00</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * 结果</span></span><br><span class="line"><span class="comment"> * 0001    p002   2  20190216    锤子  mobile 1998.00</span></span><br><span class="line"><span class="comment"> * 0002    p001   3  20190216    小米  mobile 2000.00</span></span><br><span class="line"><span class="comment"> * 0003    p002   4  20190216    锤子  mobile 1998.00</span></span><br><span class="line"><span class="comment"> * 0004    p001   5  20190216    小米  mobile 2000.00</span></span><br><span class="line"><span class="comment"> * 0005    p003   7  20190216    华为  mobile 4488.00</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wyg0405@gmail.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span> 2019-02-18 下午2:07</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Order_Map_Join</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException, URISyntaxException </span>&#123;</span><br><span class="line">        <span class="comment">//加载配置文件</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"hadoop"</span>);</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://hadoop1:9000"</span>);</span><br><span class="line">        <span class="comment">//使 NameNode 返回 DataNode 的主机名而不是 IP</span></span><br><span class="line">        conf.set(<span class="string">"dfs.client.use.datanode.hostname"</span>, <span class="string">"true"</span>);</span><br><span class="line">        <span class="comment">//启动一个Job</span></span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算程序主驱动类</span></span><br><span class="line">        job.setJarByClass(Order_Map_Join.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置Mapper及其key,value类型</span></span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(NullWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置reducer及其key,value类型</span></span><br><span class="line">        <span class="comment">/*job.setReducerClass(MyReducer.class);</span></span><br><span class="line"><span class="comment">        job.setOutputKeyClass(Text.class);</span></span><br><span class="line"><span class="comment">        job.setOutputValueClass(NullWritable.class);*/</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//将文件加载到内存，只能打jar运行,只能为文件，不能为目录</span></span><br><span class="line">        job.addCacheFile(<span class="keyword">new</span> URI(args[<span class="number">0</span>]));</span><br><span class="line">        job.setNumReduceTasks(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//输入路径</span></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line">        <span class="comment">//输出路径,该路径不能存在</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">2</span>]));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//启动job</span></span><br><span class="line">        <span class="comment">//job.submit();//无日志</span></span><br><span class="line">        job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line">        Map&lt;String, String&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        Text k = <span class="keyword">new</span> Text();</span><br><span class="line">        String result;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 读取内存中的数据</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            Path path = context.getLocalCacheFiles()[<span class="number">0</span>];</span><br><span class="line">            BufferedReader br = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(path.toString()));</span><br><span class="line">            String line;</span><br><span class="line">            <span class="keyword">while</span> ((line = br.readLine()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                String[] product = line.split(<span class="string">"\t"</span>);</span><br><span class="line">                map.put(product[<span class="number">0</span>], product[<span class="number">1</span>] + <span class="string">"\t"</span> + product[<span class="number">2</span>] + <span class="string">"\t"</span> + product[<span class="number">3</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            String[] order = value.toString().split(<span class="string">"\t"</span>);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (map.containsKey(order[<span class="number">1</span>])) &#123;</span><br><span class="line">                result = value.toString() + <span class="string">"\t"</span> + map.get(order[<span class="number">1</span>]);</span><br><span class="line">                k.set(result);</span><br><span class="line">                context.write(k, NullWritable.get());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/12-分组排序/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/12-分组排序/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Course.ava</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wyg.day09._2course;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.wyg.day08Counter.CounterTest;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * DESCRIPTION:</span></span><br><span class="line"><span class="comment"> * 分组排序，按课程分组，并按平均分由高到低排序</span></span><br><span class="line"><span class="comment"> * math	tom	89	98	34	23	56</span></span><br><span class="line"><span class="comment"> * han	tom	78	23	54	52	94	63</span></span><br><span class="line"><span class="comment"> * english	tom	45	36	98	52	74</span></span><br><span class="line"><span class="comment"> * computer	tom	67	23	89	44	86</span></span><br><span class="line"><span class="comment"> * math	lucy	45	25	66	88	44</span></span><br><span class="line"><span class="comment"> * han	lucy	78	78	45	62	87</span></span><br><span class="line"><span class="comment"> * english	lucy	89	84	66	98	21</span></span><br><span class="line"><span class="comment"> * computer	lucy	25	78	41	62	41</span></span><br><span class="line"><span class="comment"> * math	sum	56	89	54	75	12</span></span><br><span class="line"><span class="comment"> * han	sum	29	12	45	78	32</span></span><br><span class="line"><span class="comment"> * english	sum	62	12	21	45	78</span></span><br><span class="line"><span class="comment"> * computer	sum	67	45	78	12	98</span></span><br><span class="line"><span class="comment"> * math	lily	14	87	52	16	45</span></span><br><span class="line"><span class="comment"> * han	lily	67	45	78	12	32</span></span><br><span class="line"><span class="comment"> * english	lily	88	12	45	78	12</span></span><br><span class="line"><span class="comment"> * computer	lily	96	78	45	12	74</span></span><br><span class="line"><span class="comment"> * math	jim	34	45	46	89	12</span></span><br><span class="line"><span class="comment"> * han	jim	67	23	89	54	78</span></span><br><span class="line"><span class="comment"> * english	jim	48	45	78	12	45</span></span><br><span class="line"><span class="comment"> * computer	jim	35	12	45	78	45</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wyg0405@gmail.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span> 2019-02-14 11:09</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Course</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">CourseEntity</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">        Text v = <span class="keyword">new</span> Text();</span><br><span class="line">        CourseEntity courseEntity = <span class="keyword">new</span> CourseEntity();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            String[] line = value.toString().split(<span class="string">"\t"</span>);</span><br><span class="line">            <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">double</span> sum = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &lt; line.length; i++) &#123;</span><br><span class="line">                sum += Double.parseDouble(line[i]);</span><br><span class="line">                count++;</span><br><span class="line">            &#125;</span><br><span class="line">            courseEntity.setCourse(line[<span class="number">0</span>]);</span><br><span class="line">            courseEntity.setAvg(sum / count);</span><br><span class="line">            v.set(line[<span class="number">1</span>]);</span><br><span class="line">            context.write(courseEntity, v);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">CourseEntity</span>, <span class="title">Text</span>, <span class="title">CourseEntity</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">        Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(CourseEntity key, Iterable&lt;Text&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="keyword">for</span> (Text text : values) &#123;</span><br><span class="line">                v.set(text.toString());</span><br><span class="line">                context.write(key, v);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">//加载配置文件</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"hadoop"</span>);</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://hadoop1:9000"</span>);</span><br><span class="line">        <span class="comment">//使 NameNode 返回 DataNode 的主机名而不是 IP</span></span><br><span class="line">        conf.set(<span class="string">"dfs.client.use.datanode.hostname"</span>, <span class="string">"true"</span>);</span><br><span class="line">        <span class="comment">//启动一个Job</span></span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算程序主驱动类</span></span><br><span class="line">        job.setJarByClass(CounterTest.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置Mapper及其key,value类型</span></span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(CourseEntity.class);</span><br><span class="line">        job.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置reducer及其key,value类型</span></span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        job.setOutputKeyClass(CourseEntity.class);</span><br><span class="line">        job.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">//输入路径</span></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(<span class="string">"/input/course3"</span>));</span><br><span class="line">        <span class="comment">//输出路径,该路径不能存在</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"/output/course3/4"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//启动job</span></span><br><span class="line">        <span class="comment">//job.submit();//无日志</span></span><br><span class="line">        job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>CourseEntity.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wyg.day09._2course;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * DESCRIPTION:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wyg0405@gmail.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span> 2019-02-14 11:17</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CourseEntity</span> <span class="keyword">implements</span> <span class="title">WritableComparable</span>&lt;<span class="title">CourseEntity</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String course;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">double</span> avg;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CourseEntity</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CourseEntity</span><span class="params">(String course, <span class="keyword">double</span> avg)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.course = course;</span><br><span class="line">        <span class="keyword">this</span>.avg = avg;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getCourse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> course;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCourse</span><span class="params">(String course)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.course = course;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getAvg</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> avg;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAvg</span><span class="params">(<span class="keyword">double</span> avg)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.avg = avg;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span>  course +</span><br><span class="line">                <span class="string">"\t"</span> + avg ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//先对分组字段排序</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(CourseEntity o)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> courseCompare = <span class="keyword">this</span>.course.compareTo(o.getCourse());</span><br><span class="line">        <span class="keyword">if</span> (courseCompare == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">this</span>.avg - o.getAvg() &gt; <span class="number">0</span> ? -<span class="number">1</span> : (<span class="keyword">this</span>.avg - o.getAvg() == <span class="number">0</span> ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> courseCompare;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        dataOutput.writeUTF(course);</span><br><span class="line">        dataOutput.writeDouble(avg);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.course = dataInput.readUTF();</span><br><span class="line">        <span class="keyword">this</span>.avg = dataInput.readDouble();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>course.txt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">math	tom	89	98	34	23	56</span><br><span class="line">han	tom	78	23	54	52	94	63</span><br><span class="line">english	tom	45	36	98	52	74</span><br><span class="line">computer	tom	67	23	89	44	86</span><br><span class="line">math	lucy	45	25	66	88	44</span><br><span class="line">han	lucy	78	78	45	62	87</span><br><span class="line">english	lucy	89	84	66	98	21</span><br><span class="line">computer	lucy	25	78	41	62	41</span><br><span class="line">math	sum	56	89	54	75	12</span><br><span class="line">han	sum	29	12	45	78	32</span><br><span class="line">english	sum	62	12	21	45	78</span><br><span class="line">computer	sum	67	45	78	12	98</span><br><span class="line">math	lily	14	87	52	16	45</span><br><span class="line">han	lily	67	45	78	12	32</span><br><span class="line">english	lily	88	12	45	78	12</span><br><span class="line">computer	lily	96	78	45	12	74</span><br><span class="line">math	jim	34	45	46	89	12</span><br><span class="line">han	jim	67	23	89	54	78</span><br><span class="line">english	jim	48	45	78	12	45</span><br><span class="line">computer	jim	35	12	45	78	45</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/11-共同好友/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/11-共同好友/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Hadoop求共同好友"><a href="#Hadoop求共同好友" class="headerlink" title="Hadoop求共同好友"></a>Hadoop求共同好友</h1><h2 id="Hadoop求共同好友-1"><a href="#Hadoop求共同好友-1" class="headerlink" title="Hadoop求共同好友"></a>Hadoop求共同好友</h2><p>A:B,C,D,G</p>
<p>B:F,G</p>
<p>C:A,D</p>
<p>D:F</p>
<p>E:B,C,F</p>
<p>F:C,D,G</p>
<p>G:A,F</p>
<p>例如，A关注B,C,D,G；B关注F,G，AB共同好友G</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wyg.day09.friends;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.jobcontrol.JobControl;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * DESCRIPTION:</span></span><br><span class="line"><span class="comment"> * 求共同好友</span></span><br><span class="line"><span class="comment"> * A:B,C,D,G</span></span><br><span class="line"><span class="comment"> * B:F,G</span></span><br><span class="line"><span class="comment"> * C:A,D</span></span><br><span class="line"><span class="comment"> * D:F</span></span><br><span class="line"><span class="comment"> * E:B,C,F</span></span><br><span class="line"><span class="comment"> * F:C,D,G</span></span><br><span class="line"><span class="comment"> * G:A,F</span></span><br><span class="line"><span class="comment"> * 例如，A关注B,C,D,G；B关注F,G，AB共同好友G</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;</span></span><br><span class="line"><span class="comment"> * 最终结果</span></span><br><span class="line"><span class="comment"> * A-B G</span></span><br><span class="line"><span class="comment"> * A-C D</span></span><br><span class="line"><span class="comment"> * A-E C,B</span></span><br><span class="line"><span class="comment"> * A-F C,G,D</span></span><br><span class="line"><span class="comment"> * B-D F</span></span><br><span class="line"><span class="comment"> * B-E F</span></span><br><span class="line"><span class="comment"> * B-F G</span></span><br><span class="line"><span class="comment"> * B-G F</span></span><br><span class="line"><span class="comment"> * C-F D</span></span><br><span class="line"><span class="comment"> * C-G A</span></span><br><span class="line"><span class="comment"> * D-E F</span></span><br><span class="line"><span class="comment"> * D-G F</span></span><br><span class="line"><span class="comment"> * E-F C</span></span><br><span class="line"><span class="comment"> * E-G F</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> wyg0405@gmail.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@create</span> 2019-02-13 20:12</span></span><br><span class="line"><span class="comment"> **/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Friends</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper1</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">        Text k = <span class="keyword">new</span> Text();</span><br><span class="line">        Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            String[] user_friend = value.toString().split(<span class="string">":"</span>);</span><br><span class="line">            String[] friends = user_friend[<span class="number">1</span>].split(<span class="string">","</span>);</span><br><span class="line">            <span class="keyword">for</span> (String friend : friends) &#123;</span><br><span class="line">                k.set(friend);</span><br><span class="line">                v.set(user_friend[<span class="number">0</span>]);</span><br><span class="line">                context.write(k, v);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer1</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">        Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            StringBuffer stringBuffer = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">            <span class="keyword">for</span> (Text v : values) &#123;</span><br><span class="line">                stringBuffer.append(<span class="string">","</span>).append(v.toString());</span><br><span class="line">            &#125;</span><br><span class="line">            v.set(stringBuffer.substring(<span class="number">1</span>));</span><br><span class="line">            context.write(key, v);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper2</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">        Text k = <span class="keyword">new</span> Text();</span><br><span class="line">        Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            String[] lines = value.toString().split(<span class="string">"\t"</span>);</span><br><span class="line">            String[] users = lines[<span class="number">1</span>].split(<span class="string">","</span>);</span><br><span class="line">            <span class="keyword">for</span> (String user : users) &#123;</span><br><span class="line">                <span class="keyword">for</span> (String userNext : users) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (user.compareTo(userNext) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                        k.set(user + <span class="string">"-"</span> + userNext);</span><br><span class="line">                        v.set(lines[<span class="number">0</span>]);</span><br><span class="line">                        context.write(k, v);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer2</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">        Text v = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;Text&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            StringBuffer sb = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">            <span class="keyword">for</span> (Text t : values) &#123;</span><br><span class="line">                sb.append(<span class="string">","</span>).append(t.toString());</span><br><span class="line">            &#125;</span><br><span class="line">            v.set(sb.substring(<span class="number">1</span>));</span><br><span class="line">            context.write(key, v);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">//加载配置文件</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"hadoop"</span>);</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://hadoop1:9000"</span>);</span><br><span class="line">        <span class="comment">//使 NameNode 返回 DataNode 的主机名而不是 IP</span></span><br><span class="line">        conf.set(<span class="string">"dfs.client.use.datanode.hostname"</span>, <span class="string">"true"</span>);</span><br><span class="line">        <span class="comment">//启动一个Job</span></span><br><span class="line">        Job job = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算程序主驱动类</span></span><br><span class="line">        job.setJarByClass(Friends.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置Mapper及其key,value类型</span></span><br><span class="line">        job.setMapperClass(MyMapper1.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置reducer及其key,value类型</span></span><br><span class="line">        job.setReducerClass(MyReducer1.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        job.setNumReduceTasks(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//输入路径</span></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(<span class="string">"/input/friends"</span>));</span><br><span class="line">        <span class="comment">//输出路径,该路径不能存在</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(<span class="string">"/output/friends/4"</span>));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        Job job2 = Job.getInstance(conf);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//计算程序主驱动类</span></span><br><span class="line">        job2.setJarByClass(Friends.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置Mapper及其key,value类型</span></span><br><span class="line">        job2.setMapperClass(MyMapper2.class);</span><br><span class="line">        job2.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job2.setMapOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//设置reducer及其key,value类型</span></span><br><span class="line">        job2.setReducerClass(MyReducer2.class);</span><br><span class="line">        job2.setOutputKeyClass(Text.class);</span><br><span class="line">        job2.setOutputValueClass(Text.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//输入路径</span></span><br><span class="line">        FileInputFormat.addInputPath(job2, <span class="keyword">new</span> Path(<span class="string">"/output/friends/4"</span>));</span><br><span class="line">        <span class="comment">//输出路径,该路径不能存在</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job2, <span class="keyword">new</span> Path(<span class="string">"/output/friends/4/1"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//启动job</span></span><br><span class="line">        <span class="comment">//job.submit();//无日志</span></span><br><span class="line">        <span class="comment">//job.waitForCompletion(true);</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//job串联</span></span><br><span class="line">        JobControl jc = <span class="keyword">new</span> JobControl(<span class="string">"friend"</span>);</span><br><span class="line">        <span class="comment">//将原生job转换为可控Job</span></span><br><span class="line">        ControlledJob controlledJob1 = <span class="keyword">new</span> ControlledJob(job.getConfiguration());</span><br><span class="line">        ControlledJob controlledJob2 = <span class="keyword">new</span> ControlledJob(job2.getConfiguration());</span><br><span class="line">        <span class="comment">//添加依赖关系</span></span><br><span class="line">        controlledJob2.addDependingJob(controlledJob1);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//添加到组</span></span><br><span class="line">        jc.addJob(controlledJob1);</span><br><span class="line">        jc.addJob(controlledJob2);</span><br><span class="line">        <span class="comment">//启动,ControlledJob实现Runnable接口</span></span><br><span class="line">        Thread thread=<span class="keyword">new</span> Thread(jc);</span><br><span class="line">        thread.start();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//job完成，线程不会自动停止</span></span><br><span class="line">        <span class="keyword">while</span> (!jc.allFinished())&#123;</span><br><span class="line">            Thread.sleep(<span class="number">300</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        thread.stop();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>friend.txt</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">A:B,C,D,G</span><br><span class="line">B:F,G</span><br><span class="line">C:A,D</span><br><span class="line">D:F</span><br><span class="line">E:B,C,F</span><br><span class="line">F:C,D,G</span><br><span class="line">G:A,F</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/10-Combiner/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/10-Combiner/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Combiner"><a href="#Combiner" class="headerlink" title="Combiner"></a>Combiner</h1><p>作用：减少reduce端数据量，在map端进行一次合并，减少shuffle数据量</p>
<p>分担reducer压力，与reducer 的业务逻辑一样</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/1-Hadoop分布式安装/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/1-Hadoop分布式安装/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Hadoop分布式安装"><a href="#Hadoop分布式安装" class="headerlink" title="Hadoop分布式安装"></a>Hadoop分布式安装</h1><p>[TOC]</p>
<p><strong><code>说明</code></strong></p>
<blockquote>
<ol>
<li>本文利用四台centos6机器分别为，hadoop1,hadoop2,hadoop3,hadoop4</li>
<li>在安装hadoop成功前，所有操作均要在三台机器上做</li>
<li>有些配置文件可以先在一台机器上完成配置，然后通过scp发送到另外的机器，以减少工作量</li>
</ol>
</blockquote>
<h2 id="1-修改主机名及映射"><a href="#1-修改主机名及映射" class="headerlink" title="1.修改主机名及映射"></a>1.修改主机名及映射</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]<span class="comment"># vim /etc/sysconfig/network  ##修改主机名</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NETWORKING=yes</span><br><span class="line">HOSTNAME=hadoop1  <span class="comment">###修改为你的主机名，同理另外三台机器分别为hadoop2,hadoop3,hadoop4</span></span><br><span class="line">~</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]<span class="comment"># vim /etc/hosts  ###主机映射</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6 </span><br><span class="line"></span><br><span class="line"><span class="comment">###添加主机映射</span></span><br><span class="line">118.xxx.xxx.xxx hadoop1</span><br><span class="line">118.xxx.xxx.xxx hadoop2</span><br><span class="line">118.xxx.xxx.xxx hadoop3</span><br><span class="line">118.xxx.xxx.xxx hadoop4</span><br></pre></td></tr></table></figure>
<p>重启使之生效</p>
<p>注意一下：</p>
<blockquote>
<p>如果机器为云服务器，ip填内网ip，机器间传输快</p>
</blockquote>
<h2 id="2-创建hadoop用户"><a href="#2-创建hadoop用户" class="headerlink" title="2.创建hadoop用户"></a>2.创建hadoop用户</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop3 ~]<span class="comment"># useradd hadoop    ###添加hadoop用户</span></span><br><span class="line"></span><br><span class="line">[root@hadoop2 ~]<span class="comment"># passwd hadoop     ###给hadoop用户设置密码</span></span><br><span class="line"></span><br><span class="line">[root@hadoop3 ~]<span class="comment"># vim /etc/sudoers  ##为hadoop用户添加sudoers权限</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Allow root to run any commands anywhere </span></span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">hadoop  ALL=(ALL)       ALL  <span class="comment">###添加此行</span></span><br></pre></td></tr></table></figure>
<h2 id="3-ssh免密登陆"><a href="#3-ssh免密登陆" class="headerlink" title="3.ssh免密登陆"></a>3.ssh免密登陆</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##切换到hadoop用户</span></span><br><span class="line">[hadoop@hadoop1 ~]$ ssh-keygen</span><br><span class="line"></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/home/hadoop/.ssh/id_rsa): </span><br><span class="line">Created directory <span class="string">'/home/hadoop/.ssh'</span>.</span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved <span class="keyword">in</span> /home/hadoop/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /home/hadoop/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">1f:ab:b0:22:41:cc:04:46:53:c8:9c:97:1b:08:<span class="built_in">cd</span>:60 hadoop@hadoop1</span><br><span class="line">The key<span class="string">'s randomart image is:</span></span><br><span class="line"><span class="string">+--[ RSA 2048]----+</span></span><br><span class="line"><span class="string">|OE=..            |</span></span><br><span class="line"><span class="string">|o*=+             |</span></span><br><span class="line"><span class="string">| +. o            |</span></span><br><span class="line"><span class="string">|  +.             |</span></span><br><span class="line"><span class="string">| .      S .      |</span></span><br><span class="line"><span class="string">|  .      . o     |</span></span><br><span class="line"><span class="string">|   .  .   o      |</span></span><br><span class="line"><span class="string">|  . .  o .       |</span></span><br><span class="line"><span class="string">|   . .. .        |</span></span><br><span class="line"><span class="string">+-----------------+</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##传输密钥到节点</span></span><br><span class="line">[hadoop@hadoop1 ~]$ ssh-copy-id hadoop1</span><br><span class="line"></span><br><span class="line">The authenticity of host <span class="string">'hadoop1 (xxx.xxx.xxx.xxx)'</span> can<span class="string">'t be established.</span></span><br><span class="line"><span class="string">RSA key fingerprint is f2:8d:2a:43:b4:9d:7e:33:35:5b:ef:a7:67:87:82:08.</span></span><br><span class="line"><span class="string">Are you sure you want to continue connecting (yes/no)? yes</span></span><br><span class="line"><span class="string">Warning: Permanently added '</span>hadoop1,118.24.210.134<span class="string">' (RSA) to the list of known hosts.</span></span><br><span class="line"><span class="string">hadoop@hadoop1'</span>s password: </span><br><span class="line">Now try logging into the machine, with <span class="string">"ssh 'hadoop1'"</span>, and check <span class="keyword">in</span>:</span><br><span class="line"></span><br><span class="line">  .ssh/authorized_keys</span><br><span class="line"></span><br><span class="line">to make sure we haven<span class="string">'t added extra keys that you weren'</span>t expecting.</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop1 ~]$ </span><br><span class="line"></span><br><span class="line"><span class="comment">##同理传输密钥到其他节点</span></span><br><span class="line">[hadoop@hadoop1 ~]$ ssh-copy-id hadoop2</span><br><span class="line">[hadoop@hadoop1 ~]$ ssh-copy-id hadoop3</span><br><span class="line">[hadoop@hadoop1 ~]$ ssh-copy-id hadoop4</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##验证ssh无需密码</span></span><br><span class="line"></span><br><span class="line">[hadoop@hadoop1 ~]$ ssh hadoop1 <span class="comment">##登陆</span></span><br><span class="line">Last login: Mon Jan 21 08:41:48 2019 from 219.140.123.184</span><br><span class="line">[hadoop@hadoop1 ~]$ <span class="built_in">exit</span> <span class="comment">##退出</span></span><br><span class="line"><span class="built_in">logout</span></span><br><span class="line"></span><br><span class="line">[hadoop@hadoop1 ~]$ ssh hadoop2</span><br><span class="line">Last login: Mon Jan 21 08:41:48 2019 from 219.140.123.184</span><br><span class="line">[hadoop@hadoop2 ~]$ </span><br><span class="line">[hadoop@hadoop2 ~]$ <span class="built_in">exit</span></span><br><span class="line"><span class="built_in">logout</span></span><br><span class="line"></span><br><span class="line">[hadoop@hadoop1 ~]$ ssh hadoop3</span><br><span class="line">Last login: Mon Jan 21 08:41:49 2019 from 219.140.123.184</span><br><span class="line">[hadoop@hadoop3 ~]$ <span class="built_in">exit</span></span><br><span class="line"><span class="built_in">logout</span></span><br><span class="line">Connection to hadoop3 closed.</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop1 ~]$ ssh hadoop4</span><br><span class="line">Last login: Mon Jan 21 08:41:49 2019 from 219.140.123.184</span><br><span class="line">[hadoop@hadoop4 ~]$ <span class="built_in">exit</span></span><br><span class="line"><span class="built_in">logout</span></span><br><span class="line">Connection to hadoop4 closed.</span><br><span class="line">[hadoop@hadoop1 ~]$</span><br></pre></td></tr></table></figure>
<p>这样hadoop1可ssh免密码登陆到hadoo2,hadoop3,haoop4；另外三台机器同理配置</p>
<h2 id="4-安装JDK"><a href="#4-安装JDK" class="headerlink" title="4.安装JDK"></a>4.安装JDK</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##切换到root，并将实现下好的jdk上传至/user/local,本文安装jdk1.8.0_161</span></span><br><span class="line">[root@hadoop1 <span class="built_in">local</span>]<span class="comment"># cd /usr/local</span></span><br><span class="line">[root@hadoop1 <span class="built_in">local</span>]<span class="comment"># tar -zxvf jdk-8u161-linux-x64.tar.gz </span></span><br><span class="line"></span><br><span class="line">[root@hadoop1 <span class="built_in">local</span>]<span class="comment"># ls</span></span><br><span class="line">bin  etc  games  include  jdk1.8.0_161  jdk-8u161-linux-x64.tar.gz  lib  lib64  libexec  qcloud  sbin  share  src  yd.socket.server</span><br><span class="line"></span><br><span class="line"><span class="comment">##重命名文件夹</span></span><br><span class="line">[root@hadoop1 <span class="built_in">local</span>]<span class="comment"># mv jdk1.8.0_161 jdk8 </span></span><br><span class="line">[root@hadoop1 ~]<span class="comment"># vim /etc/profile</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##在文件尾加上</span></span><br><span class="line"><span class="comment">#Java</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk8</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment">#切换为hadoop用户</span></span><br><span class="line">[root@hadoop1 ~]$ <span class="built_in">source</span> /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment">##验证</span></span><br><span class="line">[hadoop@hadoop1 ~]$ java -version</span><br><span class="line"></span><br><span class="line">java version <span class="string">"1.8.0_161"</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_161-b12)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode</span><br></pre></td></tr></table></figure>
<p>同理在其他三台机器安装JDK</p>
<h2 id="5-安装hadoop"><a href="#5-安装hadoop" class="headerlink" title="5.安装hadoop"></a>5.安装hadoop</h2><h3 id="1-分布式系统规划"><a href="#1-分布式系统规划" class="headerlink" title="1.分布式系统规划"></a>1.分布式系统规划</h3><table>
<thead>
<tr>
<th></th>
<th>hdfs</th>
<th>yarn</th>
</tr>
</thead>
<tbody>
<tr>
<td>hadoop1</td>
<td>namenode、datanode</td>
<td>nodemanager</td>
</tr>
<tr>
<td>hadoop2</td>
<td>datanode、secondarynamenode</td>
<td>nodemanager</td>
</tr>
<tr>
<td>hadoop3</td>
<td>datanode</td>
<td>resourcemanager、nodemanager</td>
</tr>
<tr>
<td>hadoop4</td>
<td>datanode</td>
<td>nodemanager</td>
</tr>
</tbody>
</table>
<h3 id="2-hadoop环境变量配置"><a href="#2-hadoop环境变量配置" class="headerlink" title="2.hadoop环境变量配置"></a>2.hadoop环境变量配置</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 ~]$ wget http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.7.6/hadoop-2.7.6.tar.gz</span><br><span class="line">[hadoop@hadoop1 ~]$ tar -zxvf hadoop-2.7.6.tar.gz</span><br><span class="line">[hadoop@hadoop1 ~]$ mv hadoop-2.7.6 hadoop</span><br><span class="line"><span class="comment">##配置hadoop环境变量</span></span><br><span class="line">[hadoop@hadoop1 ~]$ su</span><br><span class="line">[root@hadoop1 ~]<span class="comment"># vim /etc/profile</span></span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Java</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk8</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/home/hadoop/hadoop</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line">[hadoop@hadoop1 ~]$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##验证</span></span><br><span class="line">[root@hadoop1 hadoop]<span class="comment"># su hadoop</span></span><br><span class="line">[hadoop@hadoop1 ~]$ hadoop version</span><br><span class="line"></span><br><span class="line">Hadoop 2.7.6</span><br><span class="line">Subversion https://shv@git-wip-us.apache.org/repos/asf/hadoop.git -r 085099c66cf28be31604560c376fa282e69282b8</span><br><span class="line">Compiled by kshvachk on 2018-04-18T01:33Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From <span class="built_in">source</span> with checksum 71e2695531cb3360ab74598755d036</span><br><span class="line">This <span class="built_in">command</span> was run using /home/hadoop/hadoop/share/hadoop/common/hadoop-common-2.7.6.jar</span><br></pre></td></tr></table></figure>
<h3 id="3-配置文件"><a href="#3-配置文件" class="headerlink" title="3.配置文件"></a>3.配置文件</h3><h4 id="1-修改配置文件"><a href="#1-修改配置文件" class="headerlink" title="1.修改配置文件"></a><strong>1.修改配置文件</strong></h4><p>配置文件目录</p>
<blockquote>
<p>hadoop-2.7.6/etc/hadoop/</p>
</blockquote>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 ~]$ <span class="built_in">cd</span> hadoop/etc/hadoop/</span><br></pre></td></tr></table></figure>
<h5 id="1-hadoop-env-sh"><a href="#1-hadoop-env-sh" class="headerlink" title="1.hadoop-env.sh"></a>1.hadoop-env.sh</h5><p>配置JAVA_HOME路径</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The java implementation to use.</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk8</span><br></pre></td></tr></table></figure>
<h5 id="2-core-site-xml"><a href="#2-core-site-xml" class="headerlink" title="2.core-site.xml"></a>2.core-site.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/data/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="3-hdfs-site-xml"><a href="#3-hdfs-site-xml" class="headerlink" title="3.hdfs-site.xml"></a>3.hdfs-site.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop2:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/data/hadoop/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/data/hadoop/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">~</span><br></pre></td></tr></table></figure>
<h5 id="4-yarn-site-xml"><a href="#4-yarn-site-xml" class="headerlink" title="4.yarn-site.xml"></a>4.yarn-site.xml</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="5-mapred-site-xml"><a href="#5-mapred-site-xml" class="headerlink" title="5.mapred-site.xml"></a>5.mapred-site.xml</h5><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ cp mapred-site.xml.template mapred-site.xml</span><br><span class="line">[hadoop@hadoop1 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop1:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop1:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>#####6.slaves</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop1</span><br><span class="line">hadoop2</span><br><span class="line">hadoop3</span><br><span class="line">hadoop4</span><br></pre></td></tr></table></figure>
<h3 id="4-格式化"><a href="#4-格式化" class="headerlink" title="4.格式化"></a>4.格式化</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ hadoop namenode -format  <span class="comment">##在namenode上执行格式化</span></span><br></pre></td></tr></table></figure>
<h3 id="5-启动与停止"><a href="#5-启动与停止" class="headerlink" title="5.启动与停止"></a>5.启动与停止</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ start-dfs.sh</span><br><span class="line">Starting namenodes on [hadoop1]</span><br><span class="line">hadoop1: starting namenode, logging to /home/hadoop/hadoop/logs/hadoop-hadoop-namenode-hadoop1.out</span><br><span class="line">hadoop4: starting datanode, logging to /home/hadoop/hadoop/logs/hadoop-hadoop-datanode-hadoop4.out</span><br><span class="line">hadoop3: starting datanode, logging to /home/hadoop/hadoop/logs/hadoop-hadoop-datanode-hadoop3.out</span><br><span class="line">hadoop2: starting datanode, logging to /home/hadoop/hadoop/logs/hadoop-hadoop-datanode-hadoop2.out</span><br><span class="line">hadoop1: starting datanode, logging to /home/hadoop/hadoop/logs/hadoop-hadoop-datanode-hadoop1.out</span><br><span class="line">Starting secondary namenodes [hadoop2]</span><br><span class="line">hadoop2: starting secondarynamenode, logging to /home/hadoop/hadoop/logs/hadoop-hadoop-secondarynamenode-hadoop2.out</span><br></pre></td></tr></table></figure>
<p><strong><code>注意，yarn最好在resourcemanager节点上启动</code></strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop3 hadoop]$ start-yarn.sh</span><br><span class="line">starting yarn daemons</span><br><span class="line">resourcemanager running as process 6172. Stop it first.</span><br><span class="line">hadoop2: Warning: Permanently added the RSA host key <span class="keyword">for</span> IP address <span class="string">'172.xx.0.7'</span> to the list of known hosts.</span><br><span class="line">hadoop4: Warning: Permanently added the RSA host key <span class="keyword">for</span> IP address <span class="string">'172.xx.0.4'</span> to the list of known hosts.</span><br><span class="line">hadoop1: Warning: Permanently added the RSA host key <span class="keyword">for</span> IP address <span class="string">'172.xx.0.12'</span> to the list of known hosts.</span><br><span class="line">hadoop2: starting nodemanager, logging to /home/hadoop/hadoop/logs/yarn-hadoop-nodemanager-hadoop2.out</span><br><span class="line">hadoop3: starting nodemanager, logging to /home/hadoop/hadoop/logs/yarn-hadoop-nodemanager-hadoop3.out</span><br><span class="line">hadoop4: starting nodemanager, logging to /home/hadoop/hadoop/logs/yarn-hadoop-nodemanager-hadoop4.out</span><br><span class="line">hadoop1: starting nodemanager, logging to /home/hadoop/hadoop/logs/yarn-hadoop-nodemanager-hadoop1.out</span><br></pre></td></tr></table></figure>
<p>查看进程</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hadoop1 hadoop]$ jps</span><br><span class="line">8482 NodeManager</span><br><span class="line">8167 DataNode</span><br><span class="line">8024 NameNode</span><br><span class="line">8637 Jps</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop2 hadoop]$ jps</span><br><span class="line">7571 NodeManager</span><br><span class="line">7435 SecondaryNameNode</span><br><span class="line">7740 Jps</span><br><span class="line">7325 DataNode</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop3 hadoop]$ jps</span><br><span class="line">6172 ResourceManager</span><br><span class="line">7501 DataNode</span><br><span class="line">7918 Jps</span><br><span class="line">7758 NodeManager</span><br><span class="line"></span><br><span class="line">[hadoop@hadoop4 ~]$ jps</span><br><span class="line">7280 DataNode</span><br><span class="line">7635 Jps</span><br><span class="line">7467 NodeManager</span><br></pre></td></tr></table></figure>
<p>也可以访问<a href="http://hadoop1:50070查看" target="_blank" rel="noopener">http://hadoop1:50070查看</a></p>
<h2 id="6-时间同步"><a href="#6-时间同步" class="headerlink" title="6.时间同步"></a>6.时间同步</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop1 ~]<span class="comment"># date</span></span><br><span class="line">Mon Jan 21 10:31:51 CST 2019  <span class="comment">##区正确</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##系统没有安装ntp，有则不用安装</span></span><br><span class="line">[root@hadoop1 ~]<span class="comment"># yum -y install ntpdate ntp</span></span><br><span class="line">[root@hadoop1 ~]<span class="comment"># ntpdate  ntp1.aliyun.com </span></span><br><span class="line">21 Jan 11:02:06 ntpdate[3318]: adjust time server 118.24.195.65 offset 0.016580 sec</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##如果出现</span></span><br><span class="line">21 Jan 10:43:49 ntpdate[1761]: the NTP socket is <span class="keyword">in</span> use, exiting</span><br><span class="line"><span class="comment">##先停止ntp，再ntpdate</span></span><br><span class="line">[root@hadoop1 ~]<span class="comment"># service ntpd stop</span></span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/0-大数据学习路线/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/0-大数据学习路线/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="大数据学习路线攻略"><a href="#大数据学习路线攻略" class="headerlink" title="大数据学习路线攻略"></a>大数据学习路线攻略</h1><p>2018年02月22日 11:18:54</p>
<p>经常有初学者在博客和QQ问我，自己想往大数据方向发展，该学哪些技术，学习路线是什么样的，觉得大数据很火，就业很好，薪资很高。如果自己很迷茫，为了这些原因想往大数据方向发展，也可以，那么我就想问一下，你的专业是什么，对于计算机/软件，你的兴趣是什么？是计算机专业，对操作系统、硬件、网络、服务器感兴趣？是软件专业，对软件开发、编程、写代码感兴趣？还是数学、统计学专业，对数据和数字特别感兴趣。</p>
<p>其实这就是想告诉你的大数据的三个发展方向，平台搭建/优化/运维/监控、大数据开发/ 设计/ 架构、数据分析/挖掘。请不要问我哪个容易，哪个前景好，哪个钱多。</p>
<p>先扯一下大数据的4V特征：</p>
<p>数据量大，TB-&gt;PB<br>数据类型繁多，结构化、非结构化文本、日志、视频、图片、地理位置等；<br>商业价值高，但是这种价值需要在海量数据之上，通过数据分析与机器学习更快速的挖掘出来；<br>处理时效性高，海量数据的处理需求不再局限在离线计算当中。</p>
<p>现如今，正式为了应对大数据的这几个特点，开源的大数据框架越来越多，越来越强，先列举一些常见的：</p>
<p>文件存储：Hadoop HDFS、Tachyon、KFS<br>离线计算：Hadoop MapReduce、Spark<br>流式、实时计算：Storm、Spark Streaming、S4、Heron<br>K-V、NOSQL数据库：HBase、Redis、MongoDB<br>资源管理：YARN、Mesos<br>日志收集：Flume、Scribe、Logstash、Kibana<br>消息系统：Kafka、StormMQ、ZeroMQ、RabbitMQ<br>查询分析：Hive、Impala、Pig、Presto、Phoenix、SparkSQL、Drill、Flink、Kylin、Druid<br>分布式协调服务：Zookeeper<br>集群管理与监控：Ambari、Ganglia、Nagios、Cloudera Manager<br>数据挖掘、机器学习：Mahout、Spark MLLib<br>数据同步：Sqoop<br>任务调度：Oozie</p>
<p>眼花了吧，上面的有30多种吧，别说精通了，全部都会使用的，估计也没几个。就我个人而言，主要经验是在第二个方向（开发/设计/架构），且听听我的建议吧。</p>
<p>第一章：初识Hadoop</p>
<p>1.1 学会百度与Google</p>
<p>不论遇到什么问题，先试试搜索并自己解决。Google首选，翻不过去的，就用百度吧。</p>
<p>1.2 参考资料首选官方文档</p>
<p>特别是对于入门来说，官方文档永远是首选文档。相信搞这块的大多是文化人，英文凑合就行，实在看不下去的，请参考第一步。</p>
<p>1.3 先让Hadoop跑起来</p>
<p>Hadoop可以算是大数据存储和计算的开山鼻祖，现在大多开源的大数据框架都依赖Hadoop或者与它能很好的兼容。</p>
<p>关于Hadoop,你至少需要搞清楚以下是什么：</p>
<p>Hadoop 1.0、Hadoop 2.0<br>MapReduce、HDFS<br>NameNode、DataNode<br>JobTracker、TaskTracker<br>Yarn、ResourceManager、NodeManager</p>
<p>自己搭建Hadoop，请使用第一步和第二步，能让它跑起来就行。建议先使用安装包命令行安装，不要使用管理工具安装。另外：Hadoop1.0知道它就行了，现在都用Hadoop 2.0.</p>
<p>1.4 试试使用Hadoop</p>
<p>HDFS目录操作命令；上传、下载文件命令；提交运行MapReduce示例程序；打开Hadoop WEB界面，查看Job运行状态，查看Job运行日志。知道Hadoop的系统日志在哪里。</p>
<p>1.5 你该了解它们的原理了</p>
<p>MapReduce：如何分而治之；HDFS：数据到底在哪里，什么是副本；<br>Yarn到底是什么，它能干什么；NameNode到底在干些什么；Resource Manager到底在干些什么；</p>
<p>1.6 自己写一个MapReduce程序</p>
<p>请仿照WordCount例子，自己写一个（照抄也行）WordCount程序，<br>打包并提交到Hadoop运行。你不会Java？Shell、Python都可以，有个东西叫Hadoop Streaming。如果你认真完成了以上几步，恭喜你，你的一只脚已经进来了。</p>
<p>第二章：更高效的WordCount</p>
<p>2.1 学点SQL吧</p>
<p>你知道数据库吗？你会写SQL吗？如果不会，请学点SQL吧。</p>
<p>2.2 SQL版WordCount</p>
<p>在1.6中，你写（或者抄）的WordCount一共有几行代码？给你看看我的:</p>
<p>SELECT word,COUNT(1) FROM wordcount GROUP BY word；</p>
<p>这便是SQL的魅力，编程需要几十行，甚至上百行代码，我这一句就搞定；使用SQL处理分析Hadoop上的数据，方便、高效、易上手、更是趋势。不论是离线计算还是实时计算，越来越多的大数据处理框架都在积极提供SQL接口。</p>
<p>2.3 SQL On Hadoop之Hive</p>
<p>什么是Hive？官方给的解释如下：The Apache Hive data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage and queried using SQL syntax.</p>
<p>为什么说Hive是数据仓库工具，而不是数据库工具呢？有的朋友可能不知道数据仓库，数据仓库是逻辑上的概念，底层使用的是数据库，数据仓库中的数据有这两个特点：最全的历史数据（海量）、相对稳定的；所谓相对稳定，指的是数据仓库不同于业务系统数据库，数据经常会被更新，数据一旦进入数据仓库，很少会被更新和删除，只会被大量查询。而Hive，也是具备这两个特点，因此，Hive适合做海量数据的数据仓库工具，而不是数据库工具。</p>
<p>2.4 安装配置Hive</p>
<p>请参考1.1 和 1.2 完成Hive的安装配置。可以正常进入Hive命令行。</p>
<p>2.5 试试使用Hive</p>
<p>请参考1.1 和 1.2 ，在Hive中创建wordcount表，并运行2.2中的SQL语句。<br>在Hadoop WEB界面中找到刚才运行的SQL任务。看SQL查询结果是否和1.4中MapReduce中的结果一致。</p>
<p>2.6 Hive是怎么工作的</p>
<p>明明写的是SQL，为什么Hadoop WEB界面中看到的是MapReduce任务？</p>
<p>2.7 学会Hive的基本命令</p>
<p>创建、删除表；加载数据到表；下载Hive表的数据；请参考1.2，学习更多关于Hive的语法和命令。</p>
<p>如果你已经按照《写给大数据开发初学者的话》中第一章和第二章的流程认真完整的走了一遍，那么你应该已经具备以下技能和知识点：</p>
<p>MapReduce的原理（还是那个经典的题目，一个10G大小的文件，给定1G大小的内存，如何使用Java程序统计出现次数最多的10个单词及次数）；<br>HDFS读写数据的流程；向HDFS中PUT数据；从HDFS中下载数据；<br>自己会写简单的MapReduce程序，运行出现问题，知道在哪里查看日志；<br>会写简单的SELECT、WHERE、GROUP BY等SQL语句；<br>Hive SQL转换成MapReduce的大致流程；<br>Hive中常见的语句：创建表、删除表、往表中加载数据、分区、将表中数据下载到本地；</p>
<p>从上面的学习，你已经了解到，HDFS是Hadoop提供的分布式存储框架，它可以用来存储海量数据，MapReduce是Hadoop提供的分布式计算框架，它可以用来统计和分析HDFS上的海量数据，而Hive则是SQL On Hadoop，Hive提供了SQL接口，开发人员只需要编写简单易上手的SQL语句，Hive负责把SQL翻译成MapReduce，提交运行。</p>
<p>此时，你的”大数据平台”是这样的：那么问题来了，海量数据如何到HDFS上呢？</p>
<p>第三章：把别处的数据搞到Hadoop上</p>
<p>此处也可以叫做数据采集，把各个数据源的数据采集到Hadoop上。</p>
<p>3.1 HDFS PUT命令</p>
<p>这个在前面你应该已经使用过了。put命令在实际环境中也比较常用，通常配合shell、python等脚本语言来使用。建议熟练掌握。</p>
<p>3.2 HDFS API</p>
<p>HDFS提供了写数据的API，自己用编程语言将数据写入HDFS，put命令本身也是使用API。</p>
<p>实际环境中一般自己较少编写程序使用API来写数据到HDFS，通常都是使用其他框架封装好的方法。比如：Hive中的INSERT语句，Spark中的saveAsTextfile等。建议了解原理，会写Demo。</p>
<p>3.3 Sqoop</p>
<p>Sqoop是一个主要用于Hadoop/Hive与传统关系型数据库，Oracle、MySQL、SQLServer等之间进行数据交换的开源框架。就像Hive把SQL翻译成MapReduce一样，Sqoop把你指定的参数翻译成MapReduce，提交到Hadoop运行，完成Hadoop与其他数据库之间的数据交换。</p>
<p>自己下载和配置Sqoop（建议先使用Sqoop1，Sqoop2比较复杂）。了解Sqoop常用的配置参数和方法。</p>
<p>使用Sqoop完成从MySQL同步数据到HDFS；使用Sqoop完成从MySQL同步数据到Hive表；如果后续选型确定使用Sqoop作为数据交换工具，那么建议熟练掌握，否则，了解和会用Demo即可。</p>
<p>3.4 Flume</p>
<p>Flume是一个分布式的海量日志采集和传输框架，因为“采集和传输框架”，所以它并不适合关系型数据库的数据采集和传输。Flume可以实时的从网络协议、消息系统、文件系统采集日志，并传输到HDFS上。</p>
<p>因此，如果你的业务有这些数据源的数据，并且需要实时的采集，那么就应该考虑使用Flume。</p>
<p>下载和配置Flume。使用Flume监控一个不断追加数据的文件，并将数据传输到HDFS；Flume的配置和使用较为复杂，如果你没有足够的兴趣和耐心，可以先跳过Flume。</p>
<p>3.5 阿里开源的DataX</p>
<p>之所以介绍这个，是因为我们公司目前使用的Hadoop与关系型数据库数据交换的工具，就是之前基于DataX开发的，非常好用。</p>
<p>可以参考我的博文《异构数据源海量数据交换工具-Taobao DataX 下载和使用》。现在DataX已经是3.0版本，支持很多数据源。你也可以在其之上做二次开发。有兴趣的可以研究和使用一下，对比一下它与Sqoop。</p>
<p>第四章：把Hadoop上的数据搞到别处去</p>
<p>Hive和MapReduce进行分析了。那么接下来的问题是，分析完的结果如何从Hadoop上同步到其他系统和应用中去呢？其实，此处的方法和第三章基本一致的。</p>
<p>4.1 HDFS GET命令</p>
<p>把HDFS上的文件GET到本地。需要熟练掌握。</p>
<p>4.2 HDFS API</p>
<p>同3.2.</p>
<p>4.3 Sqoop</p>
<p>同3.3.使用Sqoop完成将HDFS上的文件同步到MySQL；使用Sqoop完成将Hive表中的数据同步到MySQL。</p>
<p>4.4 DataX</p>
<p>同3.5. 如果你认真完成了上面的学习和实践，此时，你的”大数据平台”应该是这样的：</p>
<p>如果你已经按照《写给大数据开发初学者的话2》中第三章和第四章的流程认真完整的走了一遍，那么你应该已经具备以下技能和知识点：</p>
<p>知道如何把已有的数据采集到HDFS上，包括离线采集和实时采集；你已经知道sqoop（或者还有DataX）是HDFS和其他数据源之间的数据交换工具；你已经知道flume可以用作实时的日志采集。</p>
<p>从前面的学习，对于大数据平台，你已经掌握的不少的知识和技能，搭建Hadoop集群，把数据采集到Hadoop上，使用Hive和MapReduce来分析数据，把分析结果同步到其他数据源。</p>
<p>接下来的问题来了，Hive使用的越来越多，你会发现很多不爽的地方，特别是速度慢，大多情况下，明明我的数据量很小，它都要申请资源，启动MapReduce来执行。</p>
<p>第五章：快一点吧，我的SQL</p>
<p>其实大家都已经发现Hive后台使用MapReduce作为执行引擎，实在是有点慢。因此SQL On Hadoop的框架越来越多，按我的了解，最常用的按照流行度依次为SparkSQL、Impala和Presto.这三种框架基于半内存或者全内存，提供了SQL接口来快速查询分析Hadoop上的数据。关于三者的比较，请参考1.1.</p>
<p>我们目前使用的是SparkSQL，至于为什么用SparkSQL，原因大概有以下吧：使用Spark还做了其他事情，不想引入过多的框架；Impala对内存的需求太大，没有过多资源部署。</p>
<p>5.1 关于Spark和SparkSQL</p>
<p>什么是Spark，什么是SparkSQL。<br>Spark有的核心概念及名词解释。<br>SparkSQL和Spark是什么关系，SparkSQL和Hive是什么关系。<br>SparkSQL为什么比Hive跑的快。</p>
<p>5.2 如何部署和运行SparkSQL</p>
<p>Spark有哪些部署模式？<br>如何在Yarn上运行SparkSQL？<br>使用SparkSQL查询Hive中的表。Spark不是一门短时间内就能掌握的技术，因此建议在了解了Spark之后，可以先从SparkSQL入手，循序渐进。</p>
<p>关于Spark和SparkSQL，如果你认真完成了上面的学习和实践，此时，你的”大数据平台”应该是这样的。</p>
<p>第六章：一夫多妻制</p>
<p>请不要被这个名字所诱惑。其实我想说的是数据的一次采集、多次消费。</p>
<p>在实际业务场景下，特别是对于一些监控日志，想即时的从日志中了解一些指标（关于实时计算，后面章节会有介绍），这时候，从HDFS上分析就太慢了，尽管是通过Flume采集的，但Flume也不能间隔很短就往HDFS上滚动文件，这样会导致小文件特别多。</p>
<p>为了满足数据的一次采集、多次消费的需求，这里要说的便是Kafka。</p>
<p>6.1 关于Kafka</p>
<p>什么是Kafka？Kafka的核心概念及名词解释。</p>
<p>6.2 如何部署和使用Kafka</p>
<p>使用单机部署Kafka，并成功运行自带的生产者和消费者例子。使用Java程序自己编写并运行生产者和消费者程序。Flume和Kafka的集成，使用Flume监控日志，并将日志数据实时发送至Kafka。</p>
<p>如果你认真完成了上面的学习和实践，此时，你的”大数据平台”应该是这样的。</p>
<p>这时，使用Flume采集的数据，不是直接到HDFS上，而是先到Kafka，Kafka中的数据可以由多个消费者同时消费，其中一个消费者，就是将数据同步到HDFS。</p>
<p>如果你已经按照《写给大数据开发初学者的话3》中第五章和第六章的流程认真完整的走了一遍，那么你应该已经具备以下技能和知识点：</p>
<p>为什么Spark比MapReduce快。<br>使用SparkSQL代替Hive，更快的运行SQL。<br>使用Kafka完成数据的一次收集，多次消费架构。<br>自己可以写程序完成Kafka的生产者和消费者。</p>
<p>从前面的学习，你已经掌握了大数据平台中的数据采集、数据存储和计算、数据交换等大部分技能，而这其中的每一步，都需要一个任务（程序）来完成，各个任务之间又存在一定的依赖性，比如，必须等数据采集任务成功完成后，数据计算任务才能开始运行。如果一个任务执行失败，需要给开发运维人员发送告警，同时需要提供完整的日志来方便查错。</p>
<p>第七章：越来越多的分析任务</p>
<p>不仅仅是分析任务，数据采集、数据交换同样是一个个的任务。这些任务中，有的是定时触发，有点则需要依赖其他任务来触发。当平台中有几百上千个任务需要维护和运行时候，仅仅靠crontab远远不够了，这时便需要一个调度监控系统来完成这件事。调度监控系统是整个数据平台的中枢系统，类似于AppMaster，负责分配和监控任务。</p>
<p>7.1 Apache Oozie</p>
<ol>
<li>Oozie是什么？有哪些功能？</li>
<li>Oozie可以调度哪些类型的任务（程序）？</li>
<li>Oozie可以支持哪些任务触发方式？</li>
<li>安装配置Oozie。</li>
</ol>
<p>7.2 其他开源的任务调度系统</p>
<p>Azkaban，light-task-scheduler，Zeus，等等。另外，我这边是之前单独开发的任务调度与监控系统，具体请参考《大数据平台任务调度与监控系统》。如果你认真完成了上面的学习和实践，此时，你的”大数据平台”应该是这样的：</p>
<p>第八章：我的数据要实时</p>
<p>在第六章介绍Kafka的时候提到了一些需要实时指标的业务场景，实时基本可以分为绝对实时和准实时，绝对实时的延迟要求一般在毫秒级，准实时的延迟要求一般在秒、分钟级。对于需要绝对实时的业务场景，用的比较多的是Storm，对于其他准实时的业务场景，可以是Storm，也可以是Spark Streaming。当然，如果可以的话，也可以自己写程序来做。</p>
<p>8.1 Storm</p>
<ol>
<li>什么是Storm？有哪些可能的应用场景？</li>
<li>Storm由哪些核心组件构成，各自担任什么角色？</li>
<li>Storm的简单安装和部署。</li>
<li>自己编写Demo程序，使用Storm完成实时数据流计算。</li>
</ol>
<p>8.2 Spark Streaming</p>
<ol>
<li>什么是Spark Streaming，它和Spark是什么关系？</li>
<li>Spark Streaming和Storm比较，各有什么优缺点？</li>
<li>使用Kafka + Spark Streaming，完成实时计算的Demo程序。</li>
</ol>
<p>至此，你的大数据平台底层架构已经成型了，其中包括了数据采集、数据存储与计算（离线和实时）、数据同步、任务调度与监控这几大模块。接下来是时候考虑如何更好的对外提供数据了。</p>
<p>第九章：我的数据要对外</p>
<p>通常对外（业务）提供数据访问，大体上包含以下方面。</p>
<p>离线：比如，每天将前一天的数据提供到指定的数据源（DB、FILE、FTP）等；离线数据的提供可以采用Sqoop、DataX等离线数据交换工具。<br>实时：比如，在线网站的推荐系统，需要实时从数据平台中获取给用户的推荐数据，这种要求延时非常低（50毫秒以内）。根据延时要求和实时数据的查询需要，可能的方案有：HBase、Redis、MongoDB、ElasticSearch等。<br>OLAP分析：OLAP除了要求底层的数据模型比较规范，另外，对查询的响应速度要求也越来越高，可能的方案有：Impala、Presto、SparkSQL、Kylin。如果你的数据模型比较规模，那么Kylin是最好的选择。<br>即席查询：即席查询的数据比较随意，一般很难建立通用的数据模型，因此可能的方案有：Impala、Presto、SparkSQL。</p>
<p>这么多比较成熟的框架和方案，需要结合自己的业务需求及数据平台技术架构，选择合适的。原则只有一个：越简单越稳定的，就是最好的。</p>
<p>如果你已经掌握了如何很好的对外（业务）提供数据，那么你的“大数据平台”应该是这样的：</p>
<p>第十章：牛逼高大上的机器学习</p>
<p>关于这块，我这个门外汉也只能是简单介绍一下了。数学专业毕业的我非常惭愧，很后悔当时没有好好学数学。在我们的业务中，遇到的能用机器学习解决的问题大概这么三类：</p>
<p>分类问题：包括二分类和多分类，二分类就是解决了预测的问题，就像预测一封邮件是否垃圾邮件；多分类解决的是文本的分类；<br>聚类问题：从用户搜索过的关键词，对用户进行大概的归类。<br>推荐问题：根据用户的历史浏览和点击行为进行相关推荐。</p>
<p>大多数行业，使用机器学习解决的，也就是这几类问题。入门学习线路，数学基础；机器学习实战，懂Python最好；SparkMlLib提供了一些封装好的算法，以及特征处理、特征选择的方法。</p>
<p>机器学习确实牛逼高大上，也是我学习的目标。那么，可以把机器学习部分也加进你的“大数据平台”了。</p>
<p>原文地址:<br><a href="http://www.raincent.com/content-10-10850-1.html" target="_blank" rel="noopener">http://www.raincent.com/content-10-10850-1.html</a></p>
<p><a href="javascript:void(0" target="_blank" rel="noopener"><img src="https://g.csdnimg.cn/static/user-img/anonymous-User-img.png" alt="img"></a>;)</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">John Doe</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">42</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
